

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="hyzs1220">
  <meta name="keywords" content="">
  
    <meta name="description" content="两篇论文的阅读笔记：《Rotate to Attend: Convolutional Triplet Attention Module》[code] &amp;《GINet: Graph Interaction Network for Scene Parsing》,ECCV 2020">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读-0x03">
<meta property="og:url" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/index.html">
<meta property="og:site_name" content="hyzsのblog">
<meta property="og:description" content="两篇论文的阅读笔记：《Rotate to Attend: Convolutional Triplet Attention Module》[code] &amp;《GINet: Graph Interaction Network for Scene Parsing》,ECCV 2020">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/1.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/1.jpg">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/2.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/3.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/4.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/5.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/6.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/7.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/8.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/9.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/10.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/11.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/2.jpg">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/13.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/14.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/15.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/12.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/16.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/17.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/18.png">
<meta property="og:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/19.png">
<meta property="article:published_time" content="2020-10-25T05:01:47.000Z">
<meta property="article:modified_time" content="2024-03-23T04:15:56.576Z">
<meta property="article:author" content="hyzs1220">
<meta property="article:tag" content="注意力机制">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/1.png">
  
  
  
  <title>论文阅读-0x03 - hyzsのblog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":100,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>hyzsのblog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="论文阅读-0x03"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2020-10-25 13:01" pubdate>
          2020年10月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          38 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">论文阅读-0x03</h1>
            
            
              <div class="markdown-body">
                
                <p>两篇论文的阅读笔记：《Rotate to Attend: Convolutional Triplet
Attention Module》<a target="_blank" rel="noopener" href="https://github.com/LandskapeAI/triplet-attention">[code]</a>
&amp;《GINet: Graph Interaction Network for Scene Parsing》,ECCV
2020</p>
<span id="more"></span>
<h2 id="rotate-to-attend-convolutional-triplet-attention-module">Rotate
to Attend: Convolutional Triplet Attention Module</h2>
<h3 id="introduction">Introduction</h3>
<ul>
<li><p>作者提出了一种轻量且有效的注意力机制——Triplet Attetion</p></li>
<li><p>通过使用Triplet Branch结构来<strong>捕获跨维度交互（capturing
cross dimension interaction）</strong>。对于输入张量，Triplet
Attention通过旋转操作和残差变换建立维度间的依存关系，并以可忽略的计算开销对通道和空间信息进行编码</p></li>
<li><p>关于attention机制的使用，已经有很多具有代表性的工作，不够在这方面也只是看过SENet，在此基础上改进的工作并没有太多了解，这里列举出来，然后找时间再看看</p>
<ul class="task-list">
<li><label><input type="checkbox" checked><strong>SENet</strong>(Squeeze and Excite
module)</label></li>
<li><label><input type="checkbox" checked><strong>CBAM</strong>(Convolutional Block Attention
Module)</label></li>
<li><label><input type="checkbox"><strong>BAM</strong>(Bottleneck
Attention Module)</label></li>
<li><label><input type="checkbox"><span class="math inline">\(A^2\)</span><strong>-Nets</strong>(Double
Attention Networks)</label></li>
<li><label><input type="checkbox" checked><strong>NL</strong>(Non-Local blocks)</label></li>
<li><label><input type="checkbox"><strong>GSoP-Net</strong>(Global
Second order Pooling Networks)</label></li>
<li><label><input type="checkbox"><strong>GC-Net</strong>(Global
Context Networks)</label></li>
<li><label><input type="checkbox"><strong>CC-Net</strong>(Criss-Cross
Networks)</label></li>
<li><label><input type="checkbox"><strong>SPNet</strong></label></li>
</ul></li>
<li><p><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/1.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>（a）Squeeze Excitation (SE) Module</li>
<li>（b）Convolutional Block Attention Module (CBAM)</li>
<li>（c）Global Context (GC) Module</li>
<li>（d）triplet attention</li>
<li><span class="math inline">\(\bigotimes\)</span> 代表矩阵乘法，<span class="math inline">\(\bigodot\)</span> 代表对应位置元素相乘，<span class="math inline">\(\bigoplus\)</span> 代表对应位置元素相加</li>
</ul></li>
<li><p>不过作者说上面这些方法都存在缺陷，没有去捕获跨纬度交互信息，并且作者提出的方法几乎无参数</p></li>
<li><p>与之前的方法进行对比，有两个优点：</p>
<ul>
<li>以微不足道的计算开销捕获丰富的鉴别特征表示</li>
<li>强调跨维交互的重要性而不降低维数，从而消除了通道和权值之间的间接对应关系</li>
</ul></li>
</ul>
<h3 id="triplet-attention-module">Triplet attention module</h3>
<h4 id="cbam">CBAM</h4>
<p><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/1.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>对于输入 <span class="math inline">\(\chi \in \mathbb{R}^{C \times H
\times
W}\)</span>，CBAM的注意力机制先计算其通道注意力，然后再计算空间注意力，比较简单，其计算公式为
<ul>
<li><span class="math inline">\(\omega=\sigma\left(f_{\left(\mathbf{W}_{0},
\mathbf{W}_{1}\right)}(g(\chi))+f_{\left(\mathbf{W}_{0},
\mathbf{W}_{1}\right)}(\delta(\chi))\right)\)</span></li>
<li><span class="math inline">\(g(\chi)\)</span> 代表全局平均池(global
average pooling，GAP)函数
<ul>
<li><span class="math inline">\(g(\chi)=\frac{1}{W \times H}
\sum_{i=1}^{H} \sum_{j=1}^{W} \chi_{i, j}\)</span></li>
</ul></li>
<li><span class="math inline">\(\delta(\chi)\)</span>代表全局最大值池(global max
pooling，GMP)函数
<ul>
<li><span class="math inline">\(\delta(\chi)=\max _{H,
W}(\chi)\)</span></li>
</ul></li>
<li><span class="math inline">\(\sigma\)</span> 代表sigmoid激活函数</li>
<li><span class="math inline">\(f_{\left(\mathbf{W}_{0},
\mathbf{W}_{1}\right)}(g(\chi))\)</span> 和 <span class="math inline">\(f_{\left(\mathbf{W}_{0},
\mathbf{W}_{1}\right)}(\delta(\chi))\)</span>
代表两种变换，进一步转换有：
<ul>
<li><span class="math inline">\(\omega=\sigma\left(\mathbf{W}_{1}
\operatorname{ReLU}\left(\mathbf{W}_{0} g(\chi)\right)+\mathbf{W}_{1}
\operatorname{ReLU}\left(\mathbf{W}_{0}
\delta(\chi)\right)\right)\)</span></li>
</ul></li>
<li>其中<span class="math inline">\(W_0\)</span> 和 <span class="math inline">\(W_1\)</span> 代表权重矩阵，其大小定义为 <span class="math inline">\(C \times \frac{C}{r}\)</span> 和 <span class="math inline">\(\frac{C}{r} \times C\)</span>
<ul>
<li>这里的 r 代表降维率，r 越大的话，计算复杂度越低</li>
<li>需要注意的是 MLP: <span class="math inline">\(W_0\)</span> 和 <span class="math inline">\(W_1\)</span> 的权重在CBAM中对于两个输入 <span class="math inline">\(g(\chi)\)</span> 和 <span class="math inline">\(\delta(\chi)\)</span> 共享</li>
<li>不过这样由于存在降维操作，会造成通道间关系的损失</li>
</ul></li>
</ul></li>
</ul>
<h4 id="triplet-attention">Triplet Attention</h4>
<ul>
<li>所以作者针对CBAM中存在的缺陷，提出了一种不涉及降维操作的高效轻量（几乎无参数）的注意力机制，并且关注跨维度交互信息</li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/2.png" srcset="/img/loading.gif" lazyload></li>
<li>Triplet attention由三个分支组成，给定一个输入tensor(C x H x W)
<ul>
<li>其中两个分支负责<strong>捕获通道 C 和空间维度 H 或 W
之间的跨维交互特征</strong>
<ul>
<li>将输入进入每个分支中，通过 Z-pool，然后是核大小为k×k的卷积层</li>
<li>attention权值由sigmoid激活生成，然后应用于已排列好的输入张量，然后将其恢复到原始的输入形状</li>
</ul></li>
<li>另一个分支与CBAM类似，用于构建空间的attention</li>
<li>三个分支的输出都使用简单的平均进行聚合</li>
</ul></li>
<li>跨纬度交互特征（Cross-Dimension Interaction）
<ul>
<li>作者认为一个channel池化到一个像素值，会导致空间信息的大量丢失，并且没有考虑到维度和空间之间的相互依赖关系
<ul>
<li>空间注意力（spatial attention）：关注维度的哪些部分</li>
<li>维度/通道注意力（channel attention）：关注哪些维度通道</li>
</ul></li>
<li>所以作者提出的Triplet
attention同时捕捉空间维度和输入张量通道维度之间的交互作用</li>
</ul></li>
<li>Z-pool
<ul>
<li>将C维度的Tensor缩减到2维，将该维上的平均池化特征和最大池化特征连接起来。这使得该层能够保留实际张量的丰富表示，同时缩小其深度以使进一步的计算量更轻</li>
<li><span class="math inline">\(Z-pool(\chi)=\left[\operatorname{MaxPool}_{0
d}(\chi), \operatorname{AvgPool}_{0 d}(\chi)\right]\)</span>
<ul>
<li>0d 表示第零维：<span class="math inline">\((C \times W \times H)
==&gt; (2 \times W \times H)\)</span></li>
</ul></li>
</ul></li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/3.png" srcset="/img/loading.gif" lazyload>
<ul>
<li>在H维度和C维度之间建立交互</li>
<li>输入张量 <span class="math inline">\(\chi\)</span>
沿H轴逆时针旋转90° ，得到 <span class="math inline">\(\hat{\chi}_{1}\)</span> （ W×H×C ）</li>
<li>经过Z-pool得到 <span class="math inline">\(\hat{\chi}_{1}^{*}\)</span> （ 2×H×C ）</li>
<li><span class="math inline">\(\hat{\chi}_{1}^{*}\)</span>
通过内核大小为k×k的标准卷积层，再通过批处理归一化层，得到 (1×H×C)</li>
<li>然后通过sigmoid来生成的注意力权值，在最后输出是沿着H轴进行顺时针旋转90°保持和输入的shape一致</li>
</ul></li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/4.png" srcset="/img/loading.gif" lazyload></li>
<li>在H维度和W维度之间建立交互，基本同上</li>
<li>输入张量 <span class="math inline">\(\chi\)</span>
沿W轴逆时针旋转90° ，得到 <span class="math inline">\(\hat{\chi}_{1}\)</span> （ H×C×W ）</li>
<li>经过Z-pool得到 <span class="math inline">\(\hat{\chi}_{1}^{*}\)</span> （ 2×C×W ）</li>
<li><span class="math inline">\(\hat{\chi}_{1}^{*}\)</span>
通过内核大小为k×k的标准卷积层，再通过批处理归一化层，得到 (1×C×W)</li>
<li>然后通过sigmoid来生成的注意力权值，在最后输出是沿着H轴进行顺时针旋转90°保持和输入的shape一致</li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/5.png" srcset="/img/loading.gif" lazyload></li>
<li>建立空间内部的交互</li>
<li>直接进行Z-pool得到（ 2×H×W ）</li>
<li>通过内核大小为k×k的标准卷积层，再通过批处理归一化层，得到
(1×H×W)</li>
<li>然后通过sigmoid来生成的注意力权值</li>
<li>综上所述，最终的输出y为
<ul>
<li><span class="math inline">\(y=\frac{1}{3}\left(\overline{\hat{\chi_{1}}
\sigma\left(\psi_{1}\left(\hat{\chi_{1}}^{*}\right)\right)}+\overline{\hat{\chi_{2}}
\sigma\left(\psi_{2}\left(\hat{\chi_{2}^{*}}\right)\right)}+\chi
\sigma\left(\psi_{3}\left(\hat{\chi_{3}}\right)\right)\right)\)</span>
<ul>
<li>其中<span class="math inline">\(\psi_{1}, \psi_{2} ,
\psi_{3}\)</span> 代表卷积核大小为k的标准二维卷积层</li>
</ul></li>
<li>进一步简化得到：</li>
<li><span class="math inline">\(y=\frac{1}{3}\left(\overline{\hat{\chi_{1}}
\omega_{1}}+\overline{\hat{\chi_{2}} \omega_{2}}+\chi
\omega_{3}\right)=\frac{1}{3}\left(\overline{y_{1}}+\overline{y_{2}}+y_{3}\right)\)</span></li>
</ul></li>
<li>复杂度分析（Complexity Analysis）
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/6.png" srcset="/img/loading.gif" lazyload></li>
<li>C为该层的输入通道数，r为MLP在计算通道注意力时降维使用的缩减比，用于2D卷积的核大小用k表示，k&lt;&lt;&lt;C。</li>
</ul></li>
</ul>
<h3 id="experiments">Experiments</h3>
<ul>
<li>实验部分，作者证明其有效性和高效性，比较了性能和参数量水平</li>
<li>ImageNet数据集上的分类实验
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/7.png" srcset="/img/loading.gif" lazyload></li>
<li>Single-crop error rate (%) 单次剪裁错误率(%)，complexity comparisons
in terms of network parameters (in millions) 网络参数(以百万计) and
floating point operations per second (FLOPs)每秒浮点运算</li>
</ul></li>
<li>目标检测实验
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/8.png" srcset="/img/loading.gif" lazyload></li>
<li>Object detection mAP(%) on the MS COCO validation set</li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/9.png" srcset="/img/loading.gif" lazyload></li>
<li>Object detection mAP(%) on the PASCAL VOC 2012 test set</li>
</ul></li>
<li>消融实验（Ablation Study on Branches）</li>
</ul>
<p><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/10.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="ginet-graph-interaction-network-for-scene-parsing">GINet: Graph
Interaction Network for Scene Parsing</h2>
<h3 id="introduction-1">Introduction</h3>
<ul>
<li><p>作者提出了一种图形交互单元（GI
unit）和语义上下文损失（SC-loss），利用语义上下文信息来促进基于图像区域的推理。图形交互单元能够增强卷积网络的特征表示，同时能自适应地为每个样本学习语义一致性</p></li>
<li><blockquote>
<p>具体地，基于数据集的语义知识首先被纳入图交互单元来促进视觉图的上下文推理，然后演化的视觉图特征被反投影到每个局部特征来增强其可区分力。图交互单元进一步被语义上下文损失改善其生成基于样本语义图的能力。</p>
</blockquote></li>
<li><p>上下文推理：</p>
<ul>
<li>从特征图中学习图像的一种表示，<strong>图中的顶点定义像素簇(“区域”)，而边表示这些区域在特征空间中的相似性或关系</strong></li>
<li>通过这种方法，可以在交互图空间中进行上下文推理，然后将演化后的图映射回原始空间，增强场景解析的局部表示。</li>
</ul></li>
<li><p><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/11.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>作者不仅仅是在输入图像（特征图）和图表示之间的推理（上面部分）</li>
<li>作者将语义信息（外部知识）与之进行关联，提出了图像交互单元（GI
unit），将基于数据集的语言知识整合到视觉图的特征表示中，然后将视觉图的演化表示重新投影回每个位置表示中，以增强判别能力（下面部分）。为此作者也提出了一种语义上下文损失，让其更好自适应地表示样本（在场景中出现的类别被强调，而没有出现的类别被抑制）</li>
</ul></li>
<li><p>论文地主要贡献：</p>
<ul>
<li>提出了一种新的图形交互单元(GI单元)用于上下文建模，该单元融合了基于数据集的语言知识，可以促进可视化图形上的上下文推理。此外，它还学习了基于范例的语义图</li>
<li>提出了语义上下文丢失(SC-loss)来规范训练过程，它强调出现在场景中的类别，抑制没有出现在场景中的类别</li>
</ul></li>
<li><p>场景解析的上下文建模根据是否考虑图推理，主要可分为两类</p>
<ul>
<li><p>FCN</p>
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/2.jpg" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li><p>PSPNet利用多尺度信息，提出了金字塔池模块；DeepLab v2和DeepLab
v3利用空洞卷积和空间金字塔池捕获上下文信息，该信息由不同扩张率的空洞卷积组成</p>
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/13.png" srcset="/img/loading.gif" lazyload></li>
<li>不过这种方法都是手工设置尺度参数，不能自适应的去学习，最好的方式就是每个像素都有它自己的独特的连接信息</li>
</ul></li>
<li><p>使用Non-local非局部卷积的方式来获取全局的上下文信息，针对每一个像素，去计算和其他像素之间的依赖关系</p>
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/14.png" srcset="/img/loading.gif" lazyload></li>
</ul></li>
<li><p>近期的一些工作会对Non-local进行精简，因为并不需要对所有的像素之间进行依赖关系计算</p></li>
<li><p>GCN用在语义分割中</p>
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/15.png" srcset="/img/loading.gif" lazyload></li>
<li>首先进行投射，从特征空间投射到图空间，然后对图空间进行GCN图推理，然后再反投射回特征空间</li>
</ul></li>
</ul></li>
</ul>
<h3 id="ginet">GINet</h3>
<ul>
<li><p>GI单元的目标是纳入基于数据集的语言信息，以促进局部表示</p>
<ul>
<li>GI单元以视觉和语义表示为输入，通过生成视觉图和语义图进行上下文推理</li>
<li>以视觉节点和语义节点的相似性为指导，在两个图之间进行图交互，演进节点特征</li>
</ul></li>
<li><p>对于输入的二维图现象，GINet使用resnet作为主干网络提取特征信息</p></li>
<li><p>将基于数据集的语义知识以分类实体(类)的形式提取出来，并将分类实体(类)输入到
word embedding 单词嵌入 (如GloVe)中，实现语义表示</p>
<ul>
<li>word
embedding，就是找到一个映射或者函数，生成在一个新的空间上的表达</li>
<li>GloVe（ Global Vectors for Word Representation
）：进行词的向量化表示，使得向量之间尽可能多地蕴含语义和语法的信息</li>
<li>输入：语料库；输出：词向量</li>
<li>可以把一个单词表达成一个由实数组成的向量，这些向量捕捉到了单词之间一些语义特性，比如相似性（similarity）、类比性（analogy）等。我们通过对向量的运算，比如欧几里得距离或者cosine相似度，可以计算出两个单词之间的语义相似性</li>
</ul></li>
<li><p><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/12.png" srcset="/img/loading.gif" lazyload></p></li>
<li><p>GI unit中通过图的投影（graph
projection）操作传递视觉特征和语义嵌入表示，分别构造出两个图</p>
<ul>
<li><p>GI unit的目标是纳入基于数据集的语言信息，以促进局部表示</p></li>
<li><p>GI unit以视觉表示和语义表示为输入，通过图的投影生成视觉图（visual
graph）和语义图（semantic graph）进行上下文推理</p>
<ul>
<li>视觉图（visual graph）
<ul>
<li>建立在视觉特征之上的，其中节点表示视觉区域，而边表示这些区域之间的相似性或关系</li>
<li>对于给定的视觉特征输入 <span class="math inline">\(X \in
\mathbb{R}^{L \times C}\)</span>， 其中 <span class="math inline">\(L=H
\times W\)</span> ，期望构造一个视觉图表示<span class="math inline">\(P
\in \mathbb{R}^{N \times
D}\)</span>，其中N是节点数目，D是每个节点的所期望的特征维数</li>
<li>作者引入了一个变换矩阵<span class="math inline">\(Z \in
\mathbb{R}^{N \times L}\)</span>，从而通过X进而构造得到P</li>
<li><span class="math inline">\(P=Z X W\)</span>
<ul>
<li><span class="math inline">\(W \in \mathbb{R}^{C \times
D}\)</span>是一个可以训练矩阵，Z自适应将局部特征聚合到可视化图中的一个节点</li>
</ul></li>
</ul></li>
<li>语义图（semantic graph）
<ul>
<li>依赖于数据的类别上(用word
embedding表示)，它表示了语言相关性和标签相关性</li>
<li>建立一个语义图表示<span class="math inline">\(S \in \mathbb{R}^{M
\times
D}\)</span>，其中M表示节点的数量，等于数据集中分类实体(类)的数量，D为语义图中每个节点的特征维数</li>
<li>首先使用现成的词向量对每个类别得到语义表达<span class="math inline">\(l_{i} \in \mathbb{R}^{K}\)</span> ，<span class="math inline">\(i \in\{0,1, \ldots, M-1\}, K=300\)</span></li>
<li>然后，再使用两层MLP层对语言嵌入进行调整，使之适应视觉图的交互</li>
<li><span class="math inline">\(S_{i}=M L P\left(l_{i}\right), i
\in\{0,1, \ldots, M-1\}\)</span></li>
<li><span class="math inline">\(S_{i}\)</span>代表每个类别的节点特征</li>
</ul></li>
</ul></li>
<li><p>以视觉节点和语义节点的相似性为指导，在两个图之间进行图交互，推断节点特征</p>
<ul>
<li>Visual to Semantic (V2S)
<ul>
<li>同下</li>
<li><span class="math inline">\(\widetilde{P}=f\left(\left(A_{v}+I\right) P
W_{v}\right)\)</span></li>
<li>语义图中的信息从word
embedding中抽取出来的时候是比较通用的，然后通过变换后的VisG的交互后，就变成了针对当前图片的一种语义表征。然后针对这些语义表征利用SC-loss去进一步约束每个有别的有无（可以有效的提高对小物体的识别能力）</li>
<li>同下，计算引导矩阵</li>
<li><span class="math inline">\(G_{i, j}^{v 2 s}=\frac{\exp \left(W_{s}
\widetilde{s}_{i} \cdot W_{p} \tilde{p}_{j}\right)}{\sum_{n=1}^{N} \exp
\left(W_{s} \tilde{s}_{i} \cdot W_{p}
\widetilde{p_{n}}\right)}\)</span></li>
<li>得到引导矩阵侯，对SemG图进行更新，以生成基于范例的SemG</li>
<li><span class="math inline">\(S_{o}=\beta_{v 2 s} \widetilde{S}+G^{v 2
s} \widetilde{P} W_{v 2 s}\)</span></li>
</ul></li>
<li>Semantic to Visual (S2V)
<ul>
<li>首先对SemG进行图卷积，从而得到适合与VisG进行交互的图表示<span class="math inline">\(\widetilde{S}\)</span></li>
<li><span class="math inline">\(\widetilde{S}=f\left(\left(A_{s}+I\right) S
W_{s}\right)\)</span></li>
<li><span class="math inline">\(A_{s} \in \mathbb{R}^{M \times
M}\)</span>
是一个可学习的邻接矩阵或共现矩阵，表示语义相关或标签依赖之间的联系，过梯度下降随机初始化更新，<span class="math inline">\(I\)</span> 是单位矩阵，<span class="math inline">\(W_{s} \in \mathbb{R}^{D \times D}\)</span>
是可训练矩阵参数，f 是非线性激活函数
<ul>
<li>因为邻接矩阵的对角都是0，和特征矩阵内积相当于将邻接矩阵做了加权和，节点特征的值成为了邻接矩阵的权，自身的特征被忽略。为避免这种情况，可以给A加上一个单位矩阵</li>
</ul></li>
<li>利用变换得到的SemG来促进基于VisGeP的上下文推理</li>
<li>为了得到两个节点之间的关系，计算其特征相似度作为引导矩阵<span class="math inline">\(G^{s 2 v} \in \mathbb{R}^{N \times
M}\)</span></li>
<li>对于来自 <span class="math inline">\(\operatorname{VisG}
\widetilde{P}\)</span> 的一个节点 <span class="math inline">\(\widetilde{p_{i}} \in \mathbb{R}^{D}\)</span>
和来自SemG中的节点 <span class="math inline">\(\widetilde{s_{j}} \in
\mathbb{R}^{D}\)</span> ，我们可以计算 <span class="math inline">\(\widetilde{s_{i}}\)</span> 对节点 <span class="math inline">\(\widetilde{p_{i}}\)</span> 的赋权值的引导信息</li>
<li><span class="math inline">\(G_{i, j}^{s 2 v}=\frac{\exp \left(W_{p}
\tilde{p}_{i} \cdot W_{s} \tilde{s}_{j}\right)}{\sum_{m=1}^{M} \exp
\left(W_{p} \tilde{p}_{i} \cdot W_{s}
\widetilde{s_{m}}\right)}\)</span></li>
<li>其中<span class="math inline">\(W_{p} \in \mathbb{R}^{D / 2 \times
D}\)</span> and <span class="math inline">\(W_{s} \in \mathbb{R}^{D / 2
\times
D}\)</span>是可学习的权重矩阵用来降维；得到该引导矩阵后，可以从SemG中提取信息来增强VisG的表示</li>
<li><span class="math inline">\(P_{o}=\widetilde{P}+\beta_{s 2 v} G^{s 2
v} \widetilde{S} W_{s 2 v}\)</span></li>
<li>其中<span class="math inline">\(W_{s 2 v} \in \mathbb{R}^{D \times
D}\)</span> 是可学习的权重矩阵，<span class="math inline">\(\beta_{s 2
v} \in \mathbb{R}^{N}\)</span>
是初始化为零的可学习向量，可以通过一个标准梯度来更新</li>
<li>借助引导矩阵 <span class="math inline">\(G_{s 2
v}\)</span>，有效地构建了视觉区域与语义概念之间的相关性，并将相应的语义特征纳入到视觉节点表示中</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>在GI单元中进行图交互操作，其中语义图被用来促进视觉图的上下文推理，视觉图指导提取基于范例的语义图</p></li>
<li><p>Gi unit输出：基于范例的SemG；语义信息增强的VisG</p></li>
<li><p>重用投影矩阵Z来反向投影 <span class="math inline">\(P_0\)</span>
得到二维像素特征</p>
<ul>
<li>给定VisG中的节点 <span class="math inline">\(P_{o} \in \mathbb{R}^{N
\times D}\)</span>，反投影：</li>
<li><span class="math inline">\(\tilde{X}=Z^{T} P_{o}
W_{o}+X\)</span></li>
<li><span class="math inline">\(W_{o} \in \mathbb{R}^{D \times
C}\)</span> 是一个可训练矩阵，<span class="math inline">\(Z^{T} \in
\mathbb{R}^{L \times N}\)</span> 是Z的转置矩阵，使用残差结构</li>
</ul></li>
<li><p>将GI
unit生成的交互后的视觉图通过图重投影操作来增强对每个局部可视化表示的识别能力，同时在训练阶段通过语义上下文丢失来更新和约束语义图</p>
<ul>
<li>强调场景中出现的类别，抑制没有出现的类别，使GINet能够自适应地增强每个样本的外部语义知识，改进基于范例的SemG的生成</li>
<li>首先对每一个类定义一个可学习的语义中心 <span class="math inline">\(c_{i} \in \mathbb{R}^D\)</span> ，然后对于 <span class="math inline">\(\operatorname{SemG} \widetilde{S_0}\)</span>
中的每个语义节点 <span class="math inline">\(\widetilde{s_{i}} \in
\mathbb{R}^{D}\)</span> ，在 <span class="math inline">\(\widetilde{s_{i}}\)</span> 和 <span class="math inline">\(c_i\)</span>
上通过一个简单的点积运算和sigmoid激活函数来计算分数 <span class="math inline">\(v_i\)</span> (0-1)，用BCE损失进行训练</li>
<li>SC-loss使语义图中的节点特征与不存在类别的语义质心之间的相似性最小化，并使与存在类别之间的相似性最大化</li>
<li><span class="math inline">\(Loss _{s c}=-\frac{1}{M}
\sum_{i=1}^{M}\left(y_{i} \cdot \log v_{i}\right)+\left(1-y_{i}\right)
\log \left(1-v_{i}\right)\)</span>
<ul>
<li>其中<span class="math inline">\(y_i \in \{0,1\}\)</span>
表示每个类别是否存在</li>
</ul></li>
<li>在主干的Res4上添加了一个完整的卷积分割头来获得分割结果，于是GINet由SC-loss、辅助损失（auxiliary
loss）和交叉熵损失组成</li>
<li><span class="math inline">\(Loss =\lambda \operatorname{Loss}_{s
c}+\alpha \operatorname{Loss}_{\text {aux}}+\operatorname{Loss}_{c
e}\)</span>
<ul>
<li>其中 <span class="math inline">\(\alpha\)</span> 和 <span class="math inline">\(\lambda\)</span>
都是超参数；与之前的方法相似，将辅助损失的超参数 <span class="math inline">\(\alpha\)</span> 设为0.4</li>
</ul></li>
</ul></li>
<li><p>最后使用一个1×1的Conv和一个简单的双线性上采样来获得解析结果</p></li>
</ul>
<h3 id="experiments-1">Experiments</h3>
<ul>
<li>消融实验
<ul>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/16.png" srcset="/img/loading.gif" lazyload>
<ul>
<li>将GINet与基于VisG的上下文推理方法GCU、GloRe进行了比较</li>
</ul></li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/17.png" srcset="/img/loading.gif" lazyload></li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/18.png" srcset="/img/loading.gif" lazyload>
<ul>
<li>通过引入语义图来促进可视化图上的推理，GINet获得了更准确的解析结果</li>
</ul></li>
</ul></li>
<li><img src="/2020/10/25/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x03/19.png" srcset="/img/loading.gif" lazyload></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/study/" class="category-chain-item">study</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" class="print-no-link">#注意力机制</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>论文阅读-0x03</div>
      <div>http://example.com/2020/10/25/论文阅读-0x03/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>hyzs1220</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2020年10月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/11/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x04/" title="论文阅读-0x04">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">论文阅读-0x04</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/10/20/%E6%99%9A%E5%AE%89/" title="晚安~">
                        <span class="hidden-mobile">晚安~</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
