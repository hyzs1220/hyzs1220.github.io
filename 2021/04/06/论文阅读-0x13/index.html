

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="hyzs1220">
  <meta name="keywords" content="">
  
    <meta name="description" content="论文的阅读笔记： 《 HYPERSPECTRAL IMAGE DENOISING BASED ON MULTI-STREAM DENOISING NETWORK 》, 高琰师姐的一篇论文&amp;代码 《 Joint Demosaicing and Denoising with Self Guidance 》，CVPR 2020 主要是学习一下师姐的这份代码，然后老师说可以在这个基础上多">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读-0x13">
<meta property="og:url" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/index.html">
<meta property="og:site_name" content="hyzsのblog">
<meta property="og:description" content="论文的阅读笔记： 《 HYPERSPECTRAL IMAGE DENOISING BASED ON MULTI-STREAM DENOISING NETWORK 》, 高琰师姐的一篇论文&amp;代码 《 Joint Demosaicing and Denoising with Self Guidance 》，CVPR 2020 主要是学习一下师姐的这份代码，然后老师说可以在这个基础上多">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/1.png">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/2.png">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/3.png">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/4.png">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/5.png">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/6.png">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/7.png">
<meta property="og:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/8.png">
<meta property="article:published_time" content="2021-04-06T07:08:38.000Z">
<meta property="article:modified_time" content="2024-03-23T04:15:56.584Z">
<meta property="article:author" content="hyzs1220">
<meta property="article:tag" content="图像增强与图像恢复">
<meta property="article:tag" content="高光谱图像去噪">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/1.png">
  
  
  
  <title>论文阅读-0x13 - hyzsのblog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":100,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>hyzsのblog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="论文阅读-0x13"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-04-06 15:08" pubdate>
          2021年4月6日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          43 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">论文阅读-0x13</h1>
            
            
              <div class="markdown-body">
                
                <p>论文的阅读笔记：</p>
<p>《 HYPERSPECTRAL IMAGE DENOISING BASED ON MULTI-STREAM DENOISING
NETWORK 》, 高琰师姐的一篇论文&amp;代码</p>
<p>《 Joint Demosaicing and Denoising with Self Guidance 》，CVPR
2020</p>
<p>主要是学习一下师姐的这份代码，然后老师说可以在这个基础上多改改，也是学习学习~</p>
<span id="more"></span>
<h2 id="hyperspectral-image-denoising-based-on-multi-stream-denoising-network">HYPERSPECTRAL
IMAGE DENOISING BASED ON MULTI-STREAM DENOISING NETWORK</h2>
<h3 id="abstract">Abstract</h3>
<ul>
<li>提出了一种噪声估计子网和去噪子网组成的网络，基于multi-stream去噪网络的盲去噪方法
<ul>
<li>在噪声估计子网络中，设计了一个多尺度融合模块来捕获不同尺度下的噪声</li>
<li>然后利用去噪子网得到最终去噪图像</li>
<li>emm很像CBDNet</li>
</ul></li>
<li>Hyperspectral images
(HSIs)通常由许多通道组成，从可见光谱到红外光谱。HSIs能同时获取空间和光谱信息，比其他数据源提供更丰富的场景信息</li>
<li>传统的HSI去噪方法通常采用逐波段去噪策略
<ul>
<li>将每个波段看作是一幅二维图像，然而忽略了光谱信息，这些策略往往会导致较大的光谱畸变</li>
</ul></li>
<li>与传统的二维图像去噪方法不同，块匹配4-D滤波算法是一种适用于HSIs的三维图像去噪方法。但是，该方法没有考虑到不同波段间噪声分布的不一致性，导致频谱域性能较差</li>
<li>深度学习中大多是基于特定的噪声级别去噪，一旦噪声级别发生变化，就很难达到预期的性能，导致去噪过低或过低
<ul>
<li>为了解决这一问题，研究人员成功地采用了盲去噪技术</li>
<li>一方面，利用<strong>包含不同噪声级别的噪声图像的非常大的训练数据集</strong>对去噪模型进行优化，但现有的网络要同时学习所有类型的噪声可能是非常困难的</li>
<li>另一方面，<strong>引入噪声估计或噪声标记来指导去噪过程</strong>。Zhang等人提出了一种快速灵活的去噪网络(FFDNet)，在图像去噪中表现出了相应的性能。FFDNet结合噪声图像和噪声级估计去除复杂噪声，从而达到去噪的鲁棒性。然而，不确定的噪声水平仍然会影响上述方法的性能</li>
<li>因此，设计一种广义的去噪模型具有很大的挑战性</li>
</ul></li>
</ul>
<h3 id="methodology">METHODOLOGY</h3>
<p><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/1.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>该方法的框架如图所示。它包括两个子网:1)噪声估计子网和2)去噪子网</li>
<li>噪声估计子网
<ul>
<li>为了捕获噪声特征，设置了三个不同核大小的多尺度模块，每个多尺度模块由六个block组成
<ul>
<li><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/2.png" srcset="/img/loading.gif" lazyload></li>
<li><span class="math inline">\(\mathbf{M}_{i}=\operatorname{cat}\left[B_{1},
B_{2}, \ldots, B_{6}\right]\)</span>
<ul>
<li><span class="math inline">\(\mathbf{M}_{i}\)</span>
表示第i个多尺度模块，<span class="math inline">\(B_j\)</span>
表示第j个块</li>
</ul></li>
</ul></li>
<li>这三个多尺度模块的大小分别为3×3、5×5和7×7，然后将输出连接在一起</li>
<li>利用在金字塔池化模块进一步得到多尺度描述，然后将四个通道输出再连接在一起</li>
<li>为了学习通道之间的关系特征图，使用global max pooling
(GMP)在空间域上对特征表示P进行挤压，得到一个空间向量 <span class="math inline">\(V \in \mathbb{R}^{4C \times 1 \times 1}\)</span>
，然后将V输入到两层全连接得到一个权重向量S（上面那条通路了）</li>
<li>最后用S对P进行加权，得到噪声估计</li>
</ul></li>
<li>去噪子网
<ul>
<li>使用一个UNet</li>
</ul></li>
<li>loss
<ul>
<li>特征提取和去噪都是在端到端框架下进行的。因此，采用均方误差(mean
squared error,
MSE)损失和感知损失作为基本损失函数来指导去噪模型的学习</li>
<li>MSE loss
<ul>
<li><span class="math inline">\(\mathcal{L}_{M}=M S E
\operatorname{Loss}(G, D)=\frac{1}{C H W} \sum_{t=1}^{C H
W}\left(G_{t}-D_{t}\right)^{2}\)</span></li>
</ul></li>
<li>the perceptual loss
<ul>
<li><span class="math inline">\(\mathcal{L}_{P}=\ell^{\phi, j}(G,
D)=\frac{1}{C_{j} H_{j}
W_{j}}\left\|\phi_{j}(G)-\phi_{j}(D)\right\|_{2}^{2}\)</span></li>
</ul></li>
<li>然后像CBDNet那样，使用了非对称损失，对于过高和过低的噪声损失采用不同的惩罚（非对称）
<ul>
<li><span class="math inline">\(\mathcal{L}_{\text {asymm
}}=\sum_{i}\left|\alpha-\mathbb{I}_{\left(N_{i}-N_{i}^{\prime}\right)&lt;0}\right|
\cdot\left(N_{i}-N_{i}^{\prime}\right)^{2}\)</span></li>
<li>根据经验将α设置为0.25</li>
</ul></li>
<li>综上
<ul>
<li><span class="math inline">\(\mathcal{L} = \mathcal{L}_{M} +
\mathcal{L}_{P} + \lambda_{asymm} \mathcal{L}_{asymm}\)</span></li>
</ul></li>
</ul></li>
</ul>
<h3 id="experiment">Experiment</h3>
<ul>
<li>ICVL数据集
<ul>
<li>该数据集包含201幅图像。ICVL数据集的空间分辨率为1392 ×
1300，覆盖31个光谱通道</li>
<li>为了扩展训练数据集，将每幅训练图像裁剪成大小为64 × 64 ×
31的多个patches</li>
</ul></li>
<li>使用Pavia Centre数据集来微调模型
<ul>
<li>在测试部分，在Pavia University数据集上对模型进行了评估</li>
</ul></li>
<li>这两个数据集是通过ROSIS传感器获取的，经过处理后，Pavia
Centre图像的大小为1096×715×102，而Pavia
University图像的大小为610×340×103</li>
<li>采用batch为64的Adam优化器对该方法进行了优化。学习速率初始化为 <span class="math inline">\(10^{−4}\)</span> ，使用0.0005的权重衰减</li>
<li>基于以上设置，对网络进行100个epoch的训练</li>
<li>对于噪声设置，添加噪声分为两种情况
<ul>
<li>添加噪声等级为30,50,70的AWGN</li>
<li>随机添加噪声级别为10-70的AWGN</li>
</ul></li>
</ul>
<h3 id="section">😝😜😋</h3>
<p>emm代码和论文部分都挺简单的，上次值班的时候遇到师姐，师姐说是发的一个很水的会议，感觉确实还是满水的，不过自己也没啥具体要做的东西，所以最近还是想着多看一些代码和对应的论文实现，然后去找找灵感，多看，多做记录，然后可以拿到多光谱这方面去尝试应用一下</p>
<h2 id="joint-demosaicing-and-denoising-with-self-guidance">Joint
Demosaicing and Denoising with Self Guidance</h2>
<h3 id="abstract-1">Abstract</h3>
<ul>
<li>去马赛克和去噪通常位于计算摄影流程的早期阶段，在现代相机图像处理中起着重要的作用</li>
<li>最近，一些神经网络已经显示出联合去马赛克和去噪（JDD）的有效性</li>
<li>大多数方法首先将一个拜耳原始图像（Bayer raw
image）分解成一个四通道的RGGB图像，然后将其送入一个神经网络
<ul>
<li>这种做法忽略了一个事实，即与红色和蓝色通道相比，绿色通道的采样率是双倍的</li>
</ul></li>
<li>在本文中，作者提出了一种自导引网络(self-guidance network, SGNet)
<ul>
<li>在该网络中，首先估计绿色通道，然后作为一种引导来恢复输入图像中的所有缺失值</li>
<li>此外，由于不同频率的区域在图像恢复过程中存在不同程度的退化。作者提出一个density-map
（密度地图）指导，以帮助模型处理广泛的频率范围</li>
</ul></li>
<li>图像去马赛克是图像信号处理(ISP)流程中的开始模块之一，是计算机视觉中的一个基本问题
<ul>
<li>它旨在从彩色滤波器阵列（CFA）（例如RGGB的Bayer
图案）丢失了三分之二的图像信息后，在不完整的观察中重建全分辨率彩色图像</li>
</ul></li>
<li>传统的去马赛克和去噪处理是按顺序进行的。然而，最近的研究显示了联合方法的优点</li>
<li>深度学习方法能够有效地利用原始图像中通道内和通道间的依赖性来完成缺失的信息
<ul>
<li>这些方法中的大多数将Bayer原始图像分解为四通道的RGGB图像，并将其送入神经网络</li>
<li>利用卷积神经网络本身来发现RGGB通道之间的关系，这样它们就可以互相补充来恢复缺失的像素值</li>
<li>然而，原始Bayer
图像中红色，绿色和蓝色通道的采样率不同，没有得到充分利用。与红色和蓝色通道相比，绿色通道以双倍速率采样</li>
<li><strong>充分利用绿色通道中的信息，有利于缺失像素值的恢复</strong></li>
<li>先恢复绿色通道，再利用绿色通道与红色通道之间、绿色通道与蓝色通道之间的通道间相关性来恢复RGB通道</li>
</ul></li>
<li>在这项工作中，受这些方法的启发，作者提出了一个卷积神经网络(CNN)来明确探索输入Bayer
原始图像本身的指导，用于联合去噪和去马赛克</li>
<li>一个典型的CNN对所有位置和所有图像应用相同的参数集，而不管图像中的具体内容是什么
<ul>
<li>不过频率和噪声因图像和位置而异，因此，这种内容不可知的操作将限制神经网络的泛化能力及其处理马赛克和去噪任务的能力</li>
<li>在本研究中，与传统方法类似，作者首先仅基于绿色通道进行初始估计</li>
<li>初始恢复的绿色通道作为引导，在图像上进行空间自适应卷积</li>
<li>这样，丰富的信息和绿色通道得到整合，并在不同的位置进行不同的运用</li>
</ul></li>
<li>此外，作者发现<strong>不同频率的区域在图像重建中存在不同程度的困难</strong>
<ul>
<li>在去噪和去噪的过程中，通过模型来判断哪个区域比较难处理是很有帮助的</li>
<li>这与图像去噪中的噪声图有一些相似之处，因为<strong>不同的区域和不同的图像所面临的挑战是不同的</strong></li>
<li><strong>估计图像的密度图并将其输入到模型中，使模型能够处理广泛的频率范围</strong></li>
</ul></li>
<li>主要贡献如下：
<ul>
<li>提出了一种基于density-map（密度图）和green-channel（绿色通道）引导的自导引网络(SGNet)，用于联合去马赛克和去噪</li>
<li>提出了自适应阈值边缘损失和边缘感知平滑损失两种方法来同时恢复纹理和去除噪声</li>
<li>在合成数据和真实数据集上的定量和定性实验结果表明，模型优于最先进的方法</li>
</ul></li>
<li>图像去马赛克用于从一个彩色滤波器阵列的下采样输出中重建一个完整的彩色图像
<ul>
<li>在实际应用中，由于Bayer模式经常受到噪声的干扰，通常不能独立进行马赛克处理</li>
<li>考虑到实际情况并受益于混合问题处理，越来越多的研究开始同时进行去马赛克和去噪</li>
<li>联合去马赛克和去噪可以消除处理后的错误累积</li>
</ul></li>
<li>引导图像恢复
<ul>
<li>在许多图像恢复任务中，很多以前的工作都是利用外部信息来恢复图像，这些方法也都验证了外部制导信息对图像恢复的重要性</li>
<li>然而对于图像恢复的自我引导策略的研究却很少，自我引导信息通常很难挖掘，有时需要一些先验知识
<ul>
<li>Gu等人提出了一种快速图像去噪的自引导网络，其中低分辨率分支的特征可以引导高分辨率分支的特征</li>
</ul></li>
<li>本文针对去马赛克任务提出了两种自引导方法，即绿色通道引导和密度图引导</li>
</ul></li>
</ul>
<h3 id="the-proposed-method">The Proposed Method</h3>
<p><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/3.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>为了在联合去马赛克和去噪的任务中取得良好的性能，充分利用输入的RGGB原始图像中的信息至关重要</li>
<li>在这里，作者建议探索输入图像中的绿色通道和密度信息，并使用它们作为更好的性能指导</li>
<li>RGGB原始输入图像 <span class="math inline">\(I_{RGGB}^{Bayer} \in
\mathbb R^{2H \times 2H}\)</span> 可以分解得到四个通道 <span class="math inline">\(I_{G1}^{Bayer}, I_{G2}^{Bayer}, I_{R}^{Bayer},
I_{B}^{Bayer} \in \mathbb R^{H \times W \times 1}\)</span>
，对应于Bayer模式的四个元素</li>
<li>首先对绿色通道的缺失元素进行初步估计，因为在输入的两个绿色通道 <span class="math inline">\(I_{G1}^{Bayer}, I_{G2}^{Bayer}\)</span>
中有更丰富的信息</li>
<li>绿色通道 <span class="math inline">\(\hat I_G\)</span>
的初始估算作为一个指导，并应用到主分支，帮助恢复所有通道的缺失元素</li>
<li>此外计算密度图 <span class="math inline">\(M_D\)</span>
来表示不同区域的去噪难易水平，并将该密度图作为额外的输入输入到主分支网络</li>
<li>最后给出了用于训练整个模型的损失</li>
</ul>
<h4 id="density-map-guidance">Density-map guidance</h4>
<ul>
<li>通常图像中既有高频率的复杂区域，也有低频率的平滑区域。这些区域对联合去马赛克去噪的任务提出了不同的挑战
<ul>
<li>因此，盲目地对整个图像进行同样的处理是次优的</li>
<li>受噪声图在图像去噪中成功的启发，作者设计了密度图，让网络知道输入图像每个位置的难度等级</li>
<li>在密度图中，<strong>纹理密集的区域对应高频图案，纹理较少的区域对应低频图案</strong></li>
</ul></li>
<li><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/4.png" srcset="/img/loading.gif" lazyload></li>
<li>计算方法如下
<ul>
<li>⭐ <span class="math inline">\(M_D = h(g_2(I_{gray} -
g_1(I_{gray};K_1);K_2))\)</span></li>
<li>其中 <span class="math inline">\(g_1, g_2\)</span> 为使用不同大小核
<span class="math inline">\(K_1, K_2\)</span> 的高斯模糊操作，<span class="math inline">\(h( \cdot )\)</span> 是非线性函数， <span class="math inline">\(I_{gray}\)</span> 是四个解耦信道的平均值</li>
<li><span class="math inline">\(h(X) = \frac {X-min(X)} {max(X) - min(X)
+ \epsilon}\)</span></li>
<li><span class="math inline">\(I_{gray} = ((I_{G1}^{Bayer} +
I_{G2}^{Bayer})/2 + I_{R}^{Bayer} + I_{B}^{Bayer})/3\)</span></li>
</ul></li>
<li>对图像应用高斯模糊操作 <span class="math inline">\(g_1\)</span>
后，纹理密集的区域会变得模糊，输入和输出之间的差异会非常大</li>
<li>然后对差异图应用另一个高斯模糊操作 <span class="math inline">\(g_2\)</span> ，以得到一个平滑的密度图</li>
<li>通过非线性函数将其进一步归一化到0到1的范围内，<strong>如上图所示</strong></li>
<li>然后将该估计密度图与四个解耦通道连接，作为主要重建分支的输入</li>
<li>噪声图 <span class="math inline">\(I^{noise}\)</span>
表示训练过程中添加的高斯噪声的水平</li>
</ul>
<h4 id="green-channel-guidance">Green-channel guidance</h4>
<ul>
<li><p><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/5.png" srcset="/img/loading.gif" lazyload></p></li>
<li><p>首先在Bayer图像中每2×2块中的两个位置提取绿色像素，并获得两个绿色通道，将它们与噪声图一起送到绿色通道重建分支以产生RGB输出图像的绿色通道的初始结果</p></li>
<li><p>绿色通道重构分支由一个Residual-in-Residual Dense Block
(RRDB)组成</p>
<ul>
<li>RRDB包含多层Residual连接和Dense连接</li>
</ul></li>
<li><p>在这个分支的末端使用一个depth-to-space
layer（深度-空间层）来得到一个重建的绿色通道 <span class="math inline">\(\hat I_G \in \mathbb R^{2H \times 2W \times
1}\)</span></p>
<ul>
<li>去马赛克任务与超分辨率任务有一些相似之处，因为这两个任务都需要恢复缺失的元素，并且基本上需要进行2倍的上采样</li>
<li>以前的很多方法，直接将这个重建绿色通道直接加入到原始输入 <span class="math inline">\(I_{RGGB}^{Bayer}\)</span>
中，这样在每个位置进行相同的卷积操作。作者认为这样不是最优的</li>
</ul></li>
<li><p>为此作者提出用 <span class="math inline">\(\hat I_G\)</span>
以一种新颖的方式引导主重构分支</p></li>
<li><p><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/6.png" srcset="/img/loading.gif" lazyload></p></li>
<li><p>将空间自适应卷积运算应用于主重构分支的中间特征映射，使集成过程适应绿色通道的内容</p>
<ul>
<li>空间自适应卷积是内容感知的，在不同的位置进行不同的卷积</li>
<li>它能够增加网络的容量，并有助于处理图像中不同的频率和噪声</li>
<li>对于主重构分支 <span class="math inline">\(\mathbf{v}_{j} \in
\mathbb{R}^{c^{\prime}}, j=1,2, \ldots, H \times W\)</span>
的中间特征图中位置j的特征，空间自适应卷积 <span class="math inline">\(\mathbf{o}_{i} \in \mathbb{R}^{c}, i=1,2, \ldots,
2H \times 2W\)</span> 的输出计算如下</li>
<li><span class="math inline">\(\mathbf{o}_{i} = \sum_{j \in \Omega
(i)}\left\{G(\mathbf{f}_{1}, \mathbf{f}_{2})
\mathbf{W}_{p_{i,j}}\mathbf{v}_{j} + \mathbf{b} \right\}\)</span></li>
<li><span class="math inline">\(\Omega(\cdot)\)</span> 定义了一个s ×
s大小的卷积窗口， <span class="math inline">\(\mathbf{W} \in
\mathbb{R}^{c&#39; \times c \times s \times s}\)</span> 是卷积权重，
<span class="math inline">\(p_{i,j}\)</span> 是 <span class="math inline">\(\mathbf{W}\)</span> 与 <span class="math inline">\(i,j\)</span> 相关的索引， <span class="math inline">\(\mathbf{b} \in \mathbb{R}^{c&#39;}\)</span>
表示偏差， <span class="math inline">\(\mathbf{f}_i\)</span> 是特征向量
<span class="math inline">\(\mathbf{f}\)</span> 在位置 i 处的向量</li>
<li><span class="math inline">\(\mathbf{f}\)</span> 大小为 <span class="math inline">\(2H \times 2W \times 8\)</span>
，由初始估计的绿色通道 <span class="math inline">\(\hat I_G\)</span>
经过两个卷积层得到</li>
<li><span class="math inline">\(G( \cdot, \cdot)\)</span>
是一个依赖于两个位置之间距离的高斯函数，是空间自适应卷积的核心，定义为</li>
<li><span class="math inline">\(G\left(\mathbf{f}_{i},
\mathbf{f}_{j}\right)=\exp
\left(-\frac{1}{2}\left(\mathbf{f}_{i}-\mathbf{f}_{j}\right)^{\top}\left(\mathbf{f}_{i}-\mathbf{f}_{j}\right)\right)\)</span></li>
</ul></li>
</ul>
<h4 id="training-losses">Training losses</h4>
<ul>
<li>初始的绿通道估计和最终的RGB图像重建都需要一个损失，因此引入两个损失来监督模型的训练，以获得更好的去噪性能</li>
<li><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/7.png" srcset="/img/loading.gif" lazyload></li>
<li>Adaptive-threshold edge loss——自适应阈值边缘损失算法
<ul>
<li>尽管如上所述，通过额外的密度图 <span class="math inline">\(M_D\)</span>
，网络被告知每像素的难度级别，但输入图像中的每个像素都以相同的强度进行监督。然而，在训练过程中，具有许多高频率细节的区域比其他区域的恢复更重要，更值得关注。为了解决这一问题，作者提出了一种自适应阈值边缘损失算法</li>
<li>作者将Canny边缘检测器应用于网络输出 <span class="math inline">\(I^O\)</span> 和目标RGB图像 <span class="math inline">\(I^T\)</span>
来进行边缘提取，从而获得两个二值边缘图 <span class="math inline">\(E(I^O), E(I^T)\)</span></li>
<li>不过采用个固定的低阈值的边缘检测器仍然不能满足于不同区域</li>
<li>所以作者这里就是把一幅图像分成了好几个patch <span class="math inline">\(P_i, i = 1,2\dots, n\)</span>
，然后为每一个patch找一个自适应的阈值
<ul>
<li><strong>对于边缘较多的斑块，提高低阈值；而对于边缘较少的斑块，降低阈值</strong></li>
</ul></li>
<li>低阈值 <span class="math inline">\(\theta, i = 1,2,\dots,n\)</span>
计算如下：
<ul>
<li><span class="math inline">\(\theta_i = \theta_0 + k
\frac{s_{P_i}}{max(s_{P_1},s_{P_2},\dots,s_{P_n})}, \theta_0, k &gt;
0\)</span></li>
<li><span class="math inline">\(s_{P_i}\)</span> 是 <span class="math inline">\(P_i\)</span> 中所有像素值的和</li>
</ul></li>
<li>一旦得到两个二值边缘图 <span class="math inline">\(E(I^O),
E(I^T)\)</span>
，就可以通过计算检测到的像素作为边缘像素的比例，来近似得到一个patch
<span class="math inline">\(p(E(P_i,\theta_i))\)</span> 的边缘概率</li>
<li>然后根据 <span class="math inline">\(p(E(P_i,\theta_i))\)</span>
来计算交叉熵损失，不过自然图像中，边缘区域仍然是小部分，所以在计算交叉熵损失的时候引入一个平衡权重
<span class="math inline">\(\beta\)</span>
<ul>
<li><span class="math inline">\(\begin{aligned} L_{e d g e}
&amp;=\sum_{i=1}^{n}-\beta * p\left(E\left(P_{i}^{T} ;
\theta_{i}\right)\right) * \log \left(p\left(E\left(P_{i}^{O} ;
\theta_{i}\right)\right)\right) \\ &amp;-(1-\beta)
*\left(1-p\left(E\left(P_{i}^{T} ; \theta_{i}\right)\right)\right) * \\
&amp; \log \left(1-p\left(E\left(P_{i}^{O} ;
\theta_{i}\right)\right)\right) \end{aligned}\)</span></li>
<li>其中 <span class="math inline">\(\beta\)</span> 定义为</li>
<li><span class="math inline">\(\beta = | E(I^T) |/| I^T |\)</span></li>
<li><span class="math inline">\(|E(I^T)|\)</span>
为边缘像素数，在计算出的边缘损失边缘的基础上，对具有强边缘的区域进行了严格的监督，使得小的错误导致大的惩罚</li>
</ul></li>
<li>整个过程如最上面的图一样，要比这些文字公式说明清楚明了的多</li>
</ul></li>
<li>Edge-aware smoothness loss——平滑损失
<ul>
<li>为了获得良好的去噪性能，采用全变分(TV)正则化方法平滑噪声和非预期伪影</li>
<li>然而，TV
loss在充满文本模式的区域就会失效。因此作者提出一种边缘感知平滑损失 <span class="math inline">\(L_{smooth}\)</span> ，其公式为:
<ul>
<li><span class="math inline">\(L_{\text {smooth }}=\|\nabla O \circ
\exp (-\lambda \nabla O)\|\)</span></li>
<li><span class="math inline">\(\|\nabla O\| = \|\nabla O_h \| +
\|\nabla O_v \|\)</span> ，是水平方向和垂直方向的梯度之和， <span class="math inline">\(\lambda\)</span> 是平衡边缘感知强度的参数</li>
</ul></li>
<li>即这个损失是TV loss乘以一个指数平滑项
<ul>
<li>在平滑区域，相对于纹理和边缘丰富的区域，它要大一些</li>
<li>在这种边缘感知平滑损失的情况下，模型学习在平滑区域去除噪声的同时能够保持纹理区域的边缘</li>
</ul></li>
</ul></li>
<li>总损失：
<ul>
<li><span class="math inline">\(L = L_{edge} + \lambda_1 L_{smooth} +
\lambda_2 L_{l_1} + \lambda_3 L_g\)</span></li>
<li>其中 <span class="math inline">\(L_{l_1}\)</span>
是输出图像和真实图像之间的 <span class="math inline">\(l_1\)</span>
损失，<span class="math inline">\(L_g\)</span> 是 <span class="math inline">\(\hat I_G\)</span> 和真实绿色通道图像之间的 <span class="math inline">\(l_1\)</span> 损失</li>
</ul></li>
</ul>
<h3 id="experiment-1">Experiment</h3>
<p><img src="/2021/04/06/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x13/8.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="section-1">😝😜😋</h3>
<p>感觉整篇论文还是有不少创新点的，其中针对不同频率区域，使用不同的参数进行处理是很符合现实需要的，我想着之后自己坐高光谱图像去噪啥的话，也尽量把这方面考虑进去。不过作者提到的这些想法的实现其实都还是蛮简单的，也能很好的理解，那几张图要比文字公式说明清晰多了。</p>
<p>其他方面的话，没有感觉特别的，但作者对网络的各部分都有针对地进行了改进，还是很有想法的，值得学习！噶油~</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/study/" class="category-chain-item">study</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E4%B8%8E%E5%9B%BE%E5%83%8F%E6%81%A2%E5%A4%8D/" class="print-no-link">#图像增强与图像恢复</a>
      
        <a href="/tags/%E9%AB%98%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA/" class="print-no-link">#高光谱图像去噪</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>论文阅读-0x13</div>
      <div>http://example.com/2021/04/06/论文阅读-0x13/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>hyzs1220</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2021年4月6日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/04/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x14/" title="论文阅读-0x14">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">论文阅读-0x14</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/03/08/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x12/" title="论文阅读-0x12">
                        <span class="hidden-mobile">论文阅读-0x12</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
