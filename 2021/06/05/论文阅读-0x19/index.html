

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="hyzs1220">
  <meta name="keywords" content="">
  
    <meta name="description" content="论文的阅读笔记： 《 End-to-End Object Detection with Fully Convolutional Network 》,   [code],  CVPR 2021 《 Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Networks 》,">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读-0x19">
<meta property="og:url" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/index.html">
<meta property="og:site_name" content="hyzsのblog">
<meta property="og:description" content="论文的阅读笔记： 《 End-to-End Object Detection with Fully Convolutional Network 》,   [code],  CVPR 2021 《 Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Networks 》,">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/2.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/4.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/5.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/3.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/2.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/6.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/7.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/8.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/9.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626085977109.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626086265915.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626086454586.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/img_convert/90ebd1497b981eedf8f1f7c1c50c2931.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626092238569.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626172472059.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626092195900.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/C:%5CUsers%5Cpan%5CDesktop%5C%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%5C1626092238569.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626093707637.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626093919998.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/C:%5CUsers%5Cpan%5CDesktop%5C%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%5C1626092238569.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626140101133.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626148304608.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626148321728.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626166163139.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626227193659.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228205814.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228369489.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228394714.png">
<meta property="og:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228513343.png">
<meta property="article:published_time" content="2021-06-05T10:01:44.000Z">
<meta property="article:modified_time" content="2024-03-23T04:15:56.588Z">
<meta property="article:author" content="hyzs1220">
<meta property="article:tag" content="图像增强与图像恢复">
<meta property="article:tag" content="高光谱图像去噪">
<meta property="article:tag" content="组会分享">
<meta property="article:tag" content="目标检测">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1.png">
  
  
  
  <title>论文阅读-0x19 - hyzsのblog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":100,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>hyzsのblog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="论文阅读-0x19"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-06-05 18:01" pubdate>
          2021年6月5日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          10k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          87 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">论文阅读-0x19</h1>
            
            
              <div class="markdown-body">
                
                <p>论文的阅读笔记：</p>
<p>《 End-to-End Object Detection with Fully Convolutional Network 》,   <a target="_blank" rel="noopener" href="https://github.com/Megvii-BaseDetection/DeFCN">[code]</a>,  CVPR 2021</p>
<p>《 Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Networks 》,   <a target="_blank" rel="noopener" href="https://github.com/jnjaby/DISCNet">[code]</a>,  CVPR 2021</p>
<span id="more"></span>
<h2 id="End-to-End-Object-Detection-with-Fully-Convolutional-Network">End-to-End Object Detection with Fully Convolutional Network</h2>
<h3 id="Abstract">Abstract</h3>
<ul>
<li>
<p>基于全卷积网络的主流目标检测器已经取得了令人瞩目的性能。而其中大多数仍然需要**手工设计的非最大值抑制(NMS)**后期处理，这阻碍了端到端训练</p>
<ul>
<li>
<blockquote>
<p>NMS思想，步骤如下：<br>
（1）按照分类概率排序，概率最高的框作为候选框<br>
（2）其它所有与候选框的IOU高于一个阈值（这是人工指定的超参）的框其概率被置为0<br>
（3）然后在剩余的框里寻找概率第二大的框，其它所有与第二大的框的IOU高于一个阈值的框其概率被置为0<br>
（4）依次类推<br>
（5）最终所有的框相互之间的IOU都是小于超参阈值的，或者概率被置为0了<br>
（6）剩下的所有概率非0的框就是最终的检测框</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>本文作者对丢弃NMS的情况进行了分析，结果表明一个适当的标签分配起着关键性作用</p>
</li>
<li>
<p>对于全卷积检测器，作者提出了一个<strong>Prediction-aware OneTo-One (POTO)的标签分配用于分类</strong>，从而实现端到端检测，性能可以和NMS匹配</p>
</li>
<li>
<p>此外，提出了一种简单的<strong>3D Max Filtering (3DMF)，利用多尺度特征，提高卷积在局部区域的可鉴别性</strong></p>
</li>
<li>
<blockquote>
<p>目标检测是计算机视觉中的一个基本课题，它为每幅图像预测一组带有预定义类别标签的边界框</p>
<ul>
<li>大多数主流检测器利用了一些手工设计，如基于锚定anchor-based的标签赋值和非最大抑制(NMS)</li>
<li>最近，有相当多的方法被提出，通过使用<strong>距离感知和基于分布的标签分配</strong>来消除预定义的锚框集合</li>
<li>虽然取得了显著的进步和卓越的表现，但仍然面临着抛弃NMS后期处理的挑战，虽然很多方法被提出用来改进重复删除这一问题，不过仍然没有提供有效的端到端训练策略</li>
<li>同时，许多基于递归神经网络的方法被引入使用自回归解码器来预测每个实例的边界框</li>
<li>这些方法为边界框的预测提供了自然的顺序建模。但是，它们只在一些小的数据集上进行评估而且没有使用最新的检测器，而且迭代的方式使推理过程效率低下</li>
<li>DETR引入了一种基于二部匹配的训练策略和带有并行解码器的transformers来实现端到端检测。它实现了与许多最先进的探测器竞争的性能。然而DETR目前的训练时间要长得多，在小物体上的表现相对较差</li>
</ul>
</blockquote>
</li>
<li>
<p><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1.png" srcset="/img/loading.gif" lazyload alt></p>
</li>
<li>
<p>大部分全卷积网络采用一对多的标签分配规则，即为一个ground-truth实例分配多个预测作为前景样本（），然后采用NMS后期处理（上图虚线部分）</p>
<ul>
<li>通过这种方法，可以提供足够的前景样本，以获得<strong>强大和鲁棒的特征表示</strong></li>
<li>但大量的前景样本会导致<strong>单个实例的预测框重复</strong>，不利于端到端检测</li>
<li>为了证明这一点，作者首先对不同的现有手工设计标签分配进行实证比较，然后发现一对一标签分配在后处理重复去除中起着至关重要的作用</li>
<li>不过手工设计的一对一作业仍然有一个缺点：固定的分配可能会导致歧义问题，降低特征的可辨别性，因为<strong>预定义的实例区域可能不是训练的最佳选择</strong></li>
</ul>
</li>
<li>
<p>为了解决这一问题，作者提出了一种预测感知的一对一(POTO)标签分配方法，该方法<strong>根据分类质量和回归质量同时动态分配前景样本</strong></p>
</li>
<li>
<p>对于基于FPN的现代检测器，大量的实验表明，重复的边界盒主要来自<strong>相邻尺度上最可信预测的邻近区域</strong>，为此作者设计了一个<strong>三维最大滤波(3dmax Filtering, 3DMF)</strong>，它可以作为一个可微模块嵌入到FPN头部</p>
<ul>
<li>该模块通过使用一个简单的跨相邻尺度的三维最大滤波算子来提高卷积局部区域的可判别性</li>
</ul>
</li>
<li>
<p>现在单阶段或者双阶段的检测器都严重依赖于锚定或基于锚定的方案，在这些检测器中，<strong>锚框由预定义的滑动窗口组成，这些滑动窗口被分配为具有边界框偏移量的前景或背景样本</strong></p>
</li>
<li>
<p>由于NMS是一种启发式方法，并<strong>对所有实例采用恒定的阈值</strong>，因此需要谨慎地进行调优，而且可能不够健壮，特别是在拥挤的场景中</p>
</li>
<li>
<p>基于无锚框架，本文提出了一种预测感知的一对一分类分配规则，以抛弃不可训练的NMS</p>
</li>
<li>
<p>看到这里，感觉作者主要就是针对NMS</p>
<ul>
<li>首先，因为这是个端到端网络，之前的方法都是输出多个预测作为前景样本，然后使用NMS进行后期处理，但作者发现<strong>一对一标签分配更好</strong>，而且在去除重复这方面有着重要作用，但是直接使用一对一作业的话，可能出现歧义，不是最佳的训练选择====为此，作者提出了POTO， <strong>根据分类质量和回归质量同时动态分配前景样本</strong>，大概理解起来好像是通过学习来对这个前景样本进行一定处理，然后再让网络去学习</li>
<li>同时也是因为这些前景样本都是人工选择，而且NMS也存在一定问题，作者认为目前的很多方法说到底都没有实现基于完全卷积网络的端到端目标检测，不然就是存在网络很大，计算昂贵等各种问题</li>
<li>在这就是那个3DMF，也是为了去除重复，在多尺度之间进行一个最大滤波，感觉就是直接处理掉一些不重要信息，从而减少最后面出现的重复框，也就是作者说的利用多尺度特征，提高局部区域卷积的可分辨性</li>
<li>还是再看看后面的具体实现部分吧</li>
</ul>
</li>
</ul>
<h3 id="Methodology">Methodology</h3>
<h4 id="Analysis-on-Label-Assignment">Analysis on Label Assignment</h4>
<ul>
<li>为了揭示标签分配对端到端目标检测的影响，作者在COCO数据集上构建了几个常规标签分配的消融研究，结果显示了<strong>一对多分配在特征表示上的优越性</strong>，以及<strong>一对一分配在抛弃NMS方面的潜力</strong></li>
</ul>
<p><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/2.png" srcset="/img/loading.gif" lazyload alt></p>
<ul>
<li><strong>One-to-many Label Assignment</strong>
<ul>
<li>由于NMS后期处理在密集的预测框架中被广泛采用，一对多标签分配成为一种传统的训练目标分配方式</li>
<li>充分的前景样本导致一个<strong>强大和鲁棒的特征表示</strong>
<ul>
<li>然而当丢弃NMS时，由于一对多的标签赋值的冗余前台样本，重复的误报预测可能会导致性能的显著下降，如上表FCOS再基线上的mAP下降了28.4%</li>
</ul>
</li>
<li>另外，上表中报告的mAR表示了前100分的预测的召回率
<ul>
<li>在没有NMS的情况下，<strong>一对多的分配规则会导致大量重复的高分预测</strong>，从而降低召回率</li>
<li>因此，仅依靠一对多的分配很难实现具有竞争力的端到端检测</li>
</ul>
</li>
</ul>
</li>
<li><strong>Hand-designed One-to-one Label Assignment</strong>
<ul>
<li>作者在这里评估了两个一对一标签分配规则（Anchor规则和Center规则），解释了丢弃NMS后的潜在连接
<ul>
<li>锚定规则基于视网膜网络RetinaNet，每个ground-truth实例只给分配具有最大IoU的锚点</li>
<li>中心规则基于FCOS，每个groundtruth实例只分配到预定义特征层中离实例中心最近的像素</li>
</ul>
</li>
<li>从上表也可以看出，这种一对一标签分配大大减少了有无NMS的差距，也能达到一个较好的性能</li>
<li>不过在应用一对一标签分配时，有无NMS的检测器之间的<strong>性能差距</strong>仍然不可忽视。其次，由于对每个实例的监督较少，一对一标签分配的<strong>性能仍然低于FCOS基线</strong></li>
</ul>
</li>
</ul>
<h4 id="Methods">Methods</h4>
<p><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/4.png" srcset="/img/loading.gif" lazyload alt></p>
<ul>
<li>
<p>本文中，作者为了能够去竞争端到端目标检测性能，提出了一种<strong>混合标签分配</strong>和一种新的<strong>3D最大滤波</strong>(3DMF)</p>
</li>
<li>
<p>混合标签分配由<strong>预测感知的一对一(POTO)标签分配</strong>和**改进的一对多标签分配(辅助损失)**组成</p>
</li>
<li>
<p><strong>Prediction-aware One-to-one Label Assignment</strong></p>
<ul>
<li>
<p>手工设计的一对一标签分配遵循一个固定的规则。然而，对于复杂场景中的各种实例来说，这个规则可能不是最优的，例如，中心规则对于一个偏心eccentric物体</p>
</li>
<li>
<p>因此，如果<strong>分配过程被迫将次优预测分配为唯一的前景样本，网络收敛的难度将显著增加</strong>，导致更多的假阳性预测</p>
</li>
<li>
<p>假设 $\Psi$ 为所有预测的索引集， $G$ 和 $N$ 分别对应于ground-truth实例和预测的数量，其中在密集预测探测器中 $G \ll N$  ， $\hat{\pi} \in \Pi_{G}^{N}$ 表示N个预测的G排列方式</p>
</li>
<li>
<p>POTO的目的就是想要生成一个合适的排列预测 $\hat{\pi}$ 用来作为前景样本</p>
</li>
<li>
<p>其中训练损失如下，包含一个前景损失 $\mathcal{L}<em>{f g}$ 和背景损失 $\mathcal{L}</em>{b g}$</p>
<ul>
<li>$\mathcal{L}=\sum_{i}^{G} \mathcal{L}<em>{f g}\left(\hat{p}</em>{\hat{\pi}(i)}, \hat{b}<em>{\hat{\pi}(i)} \mid c</em>{i}, b_{i}\right)+\sum_{j \in \Psi \backslash \mathcal{R}(\hat{\pi})} \mathcal{L}<em>{b g}\left(\hat{p}</em>{j}\right)$</li>
<li>其中， $\mathcal{R}(\hat{\pi})$ 表示指定前景样本对应的索引集</li>
<li>对于第 $i$ 个ground-truth，$c_i,b_i$ 分别表示其类别标签和边界框坐标</li>
<li>对应的第 $\hat{\pi}(i)$ 个预测， $\hat{p}<em>{\hat{\pi}(i)}, \hat{b}</em>{\hat{\pi}(i)}$ 对应其预测的分类分数和预测的方框坐标</li>
</ul>
</li>
<li>
<p>为了实现端到端检测，就需要找到一个合适的标签分配 $\hat{\pi}$ ，之前的工作就是将其看作一个二部图匹配问题，利用前景损失作为匹配代价，可以用匈牙利算法快速求解</p>
<ul>
<li>
<blockquote>
<p>借用SSD来理解二部图匹配策略与匈牙利算法：</p>
<p>1）建图。对于某个预测框，遍历所有的gt_bbox，如果它们的交集大于0，那么就用一条边把gt_bbox与预测框连接起来；这样对所有的预测框都进行同样操作。如果把所有gt_bbox放入集合A，所有预测框放入集合B，那么这一步就是建立A与B之间的二部图，二部图中边的权值为预测框与gt_bbox的iou分数。（这里的权值就是上文的匹配代价）</p>
<p>2）匹配。匹配分为2个阶段：</p>
<p>第一个阶段：找出二部图中的边权值最大的边，并该边对应的gt_bbox与预测框从顶点集中删除；反复进行这个过程，直到所有的gt_bbox都找到匹配的预测框；</p>
<p>第二个阶段：如果匹配的类型是BIPARTITE，那么匹配过程已结束；如果匹配类型是PER_PREDICTION，表示对于每个预测框，都要找到一个gt_bbox与之匹配，那么对于第一阶段未匹配上的预测框，从gt_bboxes集合中找到与它所连边中权值最大的gt_bbox作为它的匹配。</p>
<p>第一个阶段的匹配保证每个gt_bbox都至少有一个预测框与之匹配，这是因为预测框足够多，必定有许多预测框与gt_bbox建立边连接，且每个预测框都有0个或1个gt_bbox与之匹配。第二个阶段的匹配如果采用PER_PREDICTION方法，那么每个预测框都有且只有1个gt_bbox与之匹配了，但是gt_bbox可能匹配上多个预测框。</p>
</blockquote>
</li>
<li>
<p>$\hat{\pi}=\underset{\pi \in \Pi_{G}^{N}}{\arg \min } \sum_{i}^{G} \mathcal{L}<em>{f g}\left(\hat{p}</em>{\hat{\pi}(i)}, \hat{b}<em>{\hat{\pi}(i)} \mid c</em>{i}, b_{i}\right)$</p>
</li>
<li>
<p>但是，前景损失通常需要额外的权重来缓解优化问题，如训练样本不平衡、多任务联合训练等，这种特性使得训练损失不是匹配代价的最优选择</p>
</li>
</ul>
</li>
<li>
<p>为此作者提出了一个简单有效的POTO来寻找一个更好地分配方式：</p>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/5.png" srcset="/img/loading.gif" lazyload alt></li>
<li>$\begin{aligned} \hat{\pi} &amp;=\underset{\pi \in \Pi_{G}^{N}}{\arg \max } \sum_{i}^{G} Q_{i, \pi(i)}, \ \text { where } Q_{i, \pi(i)}=&amp; \underbrace{\mathbb{1}\left[\pi(i) \in \Omega_{i}\right]}<em>{\text {spatial prior }} \cdot \underbrace{\left(\hat{p}</em>{\pi(i)}\left(c_{i}\right)\right)^{1-\alpha}}<em>{\text {classification }} . \ &amp; \underbrace{\left(\operatorname{IoU}\left(b</em>{i}, \hat{b}<em>{\pi(i)}\right)\right)^{\alpha}}</em>{\text {regression }} . \end{aligned}$</li>
<li>这里的 $Q_{i, \pi(i)} \in [0,1]$ 表示第 $i$ 个ground-truth和 $\hat{\pi}(i)$ 个预测之间的一个<strong>匹配质量</strong>（同时考虑了空间先验、分类的置信度和回归质量）</li>
<li>$\Omega_i$ 表示第 $i$ 个ground-truth的候选预测集，也就是空间先验；</li>
<li>FCOS采用中心采样策略，只将ground-truth<strong>实例中心部分的预测作为前景样本</strong>，作者也将其应用在POTO中，以获得更高的性能，但并不需要抛弃NMS</li>
<li>在上式中，使用分类得分 $\hat{p}<em>{\pi(i)}\left(c</em>{i}\right)$ 和回归质量 $\operatorname{IoU}(b_{i}, \hat{b}_{\pi(i)})$ 的加权几何平均值来定义质量</li>
<li>超参数 $\alpha \in [0,1]$ 调整分类与回归之间的比值，其中默认采用 $\alpha =0.8$</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>3D Max Filtering</strong></p>
<ul>
<li>作者发现重复预测主要来自于<strong>最可信预测的邻近空间区域</strong>。因此提出了一个新的模块，称为3D Max Filtering (3DMF)，以<strong>抑制重复预测</strong></li>
<li>卷积是一种具有平移等方差的线性运算，<strong>对不同位置的相似模式产生相似的输出</strong>。但是，由于<strong>相同实例的不同预测</strong>对于密集预测检测器来说通常<strong>具有相似的特征</strong>，所以这个属性对于消除重复预测有很大的障碍</li>
<li>Max滤波器是一种基于秩的非线性滤波器，用于补偿局部区域内卷积的判别能力，也可以被作为一个新的后期处理步骤来取代非最大抑制
<ul>
<li>它展示了一些执行重复去除的潜力，但非可训练的方式妨碍了有效性和端到端的训练。同时，最大滤波器只考虑了单尺度特征，不适用于广泛应用的基于FPN的检测器</li>
</ul>
</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/3.png" srcset="/img/loading.gif" lazyload alt></li>
<li>因此作者在这里就是扩展成多尺度的版本——3D Max Filtering，在FPN的每个尺度上进行特征转换， 在feature map的每个通道上分别采用3D Max滤波
<ul>
<li>$\tilde{x}^{s}=\left{\tilde{x}^{s, k}:=\operatorname{Bilinear}_{x^{s}}\left(x^{k}\right) \mid \forall k \in\left[s-\frac{\tau}{2}, s+\frac{\tau}{2}\right]\right}$</li>
<li>给定FPN的尺度 $s$ 中的一个输入特征 $x^s$ ，首先采用双线性算子对 $\tau$ 相邻尺度的<strong>相邻特征插值到与输入 $x^s$ 相同的尺度</strong></li>
<li>$y_{i}^{s}=\max <em>{k \in\left[s-\frac{\tau}{2}, s+\frac{\tau}{2}\right]} \max <em>{j \in \mathcal{N}</em>{i}^{\phi \times \phi}} \tilde{x}</em>{j}^{s, k}$</li>
<li>对于 $s$ 尺度下的空间位置 $i$ ，在预先定义的三维中，根据比例 $\tau$ 尺度和 $\phi \times \phi$ 的空间距离，得到最大值 $y_i^s$ 。这个操作可以通过高效的<strong>3D max-pooling运算</strong>轻松实现</li>
</ul>
</li>
<li>此外，为了将3D Max  Filtering嵌入到现有框架中，实现端到端训练，作者提出了一个新的模块，如上图</li>
<li>该模块利用最大滤波来选择<strong>局部区域中激活值最高的预测</strong>，可以增强与其他预测的区别，这在后文中得到了进一步的验证。由于这一特性，作者<strong>采用3DMF对粗密预测进行细化，抑制重复预测</strong>。此外，所有的模块都是由简单的可微算子构造的，计算开销很小</li>
</ul>
</li>
<li>
<p><strong>Auxiliary Loss</strong></p>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/2.png" srcset="/img/loading.gif" lazyload alt></li>
<li>在使用NMS时，如上表所示，POTO和3DMF的性能仍然低于FCOS基线</li>
<li>作者认为这种现象可能是由于<strong>一对一的标签分配提供较少的监督</strong>，使得网络很难学习强大和鲁棒的特征表示</li>
<li>为此引入了一个基于one-to-many的标签分配的辅助损耗，以提供足够的监督</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/6.png" srcset="/img/loading.gif" lazyload alt></li>
<li>与ATSS相似，辅助损失采用了改进的one-to-many标签分配的focal loss</li>
<li>one-to-many标签分配首先根据上面提出的匹配质量，在每个FPN阶段将<strong>前9个预测作为候选</strong>。然后将匹配质量超过<strong>统计阈值</strong>（统计阈值由所有候选匹配质量的均值和标准差的总和计算）的候选样本作为前景样本分配</li>
</ul>
</li>
</ul>
<h3 id="Experiments">Experiments</h3>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/7.png" srcset="/img/loading.gif" lazyload alt></li>
<li>上图展示了从FCOS基线和提出的框架得到的分类分数的可视化
<ul>
<li>例如，一对多任务的FCOS基线输出了<strong>大量重复的预测</strong>，这些预测是高度激活的，与最自信的预测具有可比性的激活分数，这些重复的预测被评估为假阳性样本，并极大地影响性能</li>
<li>与此相反，通过使用所提出的POTO规则，重复样本的得分被显著地抑制。该特性对于探测器在没有NMS的情况下实现直接边界框预测至关重要</li>
<li>此外，通过提出的3DMF模块，进一步增强了这一特性，特别是在最自信的预测附近区域，同时由于3DMF模块引入了多尺度竞争机制，检测器可以很好地在FPN的不同阶段进行独特的预测，如上图中的一个实例<strong>在各个阶段有一个高度激活的分数</strong></li>
</ul>
</li>
<li>做的一些消融实验，直接看实验结果表格吧，不解释了，，，</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/8.png" srcset="/img/loading.gif" lazyload alt></li>
<li>为了弥补全卷积网络与端到端目标检测之间的差距，本文提出了一种基于predict-aware one-to-one标签分配策略和3D Max Filtering 方法。在引入辅助损失的情况下，本文端到端框架在COCO和CrowdHuman数据集上使用NMS实现了比许多先进检测器更优越的性能。在复杂拥挤的场景中也显示了巨大的潜力，这可能有利于许多其他实例级任务。附录的检测对比图，如下图所示，在有目标重叠情况下，带有NMS的FCOS确实是会去掉一些预测正确的框，而留下一些虚警，而论文提出的方法在此方面有较好的效果</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/9.png" srcset="/img/loading.gif" lazyload alt></li>
</ul>
<h3 id="😝😜😋">😝😜😋</h3>
<p>目标检测的论文确实要比图像增强去噪这方面复杂不少，这篇论文里面，作者确实是提出了很多想法，也许是我没读过太多这方面的论文吧，不过确实还是感觉很强的</p>
<p>说到底，作者就是针对NMS这一算法，想要给替换掉，然后想着使用一对一标签进行端到端学习，于是提出了使用predict-aware one-to-one标签分配策略和3D Max Filtering 方法，同时引入了一个辅助损失来提供更多的监督信息，网络结构部分就是3DM那个信息的流动方向没太看懂，再研究研究，然后别的部分都还好，刚开始读这种目标检测的论文，确实有点吃力，里面说的很多名词都没怎么接触过，不太好理解，，，</p>
<h2 id="Removing-Diffraction-Image-Artifacts-in-Under-Display-Camera-via-Dynamic-Skip-Connection-Networks">Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Networks</h2>
<p>通过动态跳跃连接网络消除屏下相机图像中的由于衍射产生的痕迹</p>
<h3 id="Abstract-2">Abstract</h3>
<ul>
<li>
<p>屏下相机  (Under-Display Camera, UDC)</p>
<ul>
<li>消费者对无边框、无凹槽显示屏智能手机的需求引发了手机制造商对新定义的成像系统UDC的兴趣
<ul>
<li>手机全面屏发展：刘海屏-水滴屏-挖孔屏-<strong>屏下摄像头</strong></li>
</ul>
</li>
<li>此外在视频会议中，使用UDC将相机放置在显示器的中心时，能够实现更自然的凝视聚焦</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626085977109.png" srcset="/img/loading.gif" lazyload alt="1626085977109"></li>
</ul>
</li>
<li>
<p>在典型的UDC系统中，半透明有机发光二极管(organic light-emitting diode, OLED)像素阵列的微结构会<strong>衰减并衍射相机上的入射光</strong>，导致图像质量显著下降</p>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626086265915.png" srcset="/img/loading.gif" lazyload alt="1626086265915"></li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626086454586.png" srcset="/img/loading.gif" lazyload alt="1626086454586">
<ul>
<li><strong>中兴Axon 20手机</strong>上UDC OLED的特写——<strong>降低了摄像头上方区域的像素密度，从而提高了透明度</strong></li>
</ul>
</li>
<li>典型的UDC系统将相机模块放置在半透明有机发光二极管(OLED)显示器的下方并与之紧密相连
<ul>
<li><strong>OLED屏幕本身就是透光的，不过透光不是很多</strong>（5%）</li>
</ul>
</li>
<li>尽管显示器看起来是部分透明的，但是光可以通过的区域，即显示像素之间的间隙，通常是微米级的，这基本上<strong>衍射了从场景到传感器的入射光</strong></li>
<li><img src="https://img-blog.csdnimg.cn/img_convert/90ebd1497b981eedf8f1f7c1c50c2931.png" srcset="/img/loading.gif" lazyload alt="光栅衍射主极大个数_大学物理——光的干涉和衍射（二）_weixin_39633452的博客-CSDN博客"></li>
<li>市面上主流的手机屏幕的像素密度大概为 $300-400,500-600 ppi, 400 ppi \approx 63 \mu m / pixel$ ，像素之间的空隙则要更小，已经满足了相关条件，所以更<strong>会发生光的衍射，不可忽略</strong></li>
</ul>
</li>
<li>
<p>在这项工作中，作者旨在分析和解决上述退化问题，定义了一个<strong>基于物理的图像形成模型</strong>，以更好地理解退化</p>
<ul>
<li>作者利用世界上最早的商品UDC智能手机原型之一来测量UDC系统的真实世界 <strong>点扩散函数(Point Spread Function, PSF)</strong>，并提供<strong>基于模型的数据合成流程来生成真实的降级图像</strong>
<ul>
<li>这里的点扩散函数，就是说给一个成像系统一个点冲击的时候，它感受器产生的结果</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626092238569.png" srcset="/img/loading.gif" lazyload alt="1626092238569"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>作者专门设计了一个新的领域知识支持的**动态跳跃连接网络Dynamic Skip Connection Network, DISCNet)**来恢复UDC图像</p>
<ul>
<li>将图像形成模型的领域知识结合到网络设计中</li>
<li><strong>将PSF作为一个附加条件</strong>，将其输入到一个条件编码器中，以便于<strong>动态滤波器的生成</strong></li>
<li>在这项工作中，作者构建了<strong>多尺度滤波器生成器</strong>，并<strong>在特征域中采用动态卷积来处理大支持度和长尾PSF的退化</strong></li>
</ul>
</li>
<li>
<p>基于物理的图像形成模型和提出的DISCNet可以为UDC图像恢复的进一步探索提供基础，甚至为更广泛意义上的一般衍射伪影去除提供基础</p>
</li>
<li>
<p>在解决UDC图像恢复问题的第一次尝试（2020年的一篇论文）中，作者提出了一种<strong>监控摄像机成像系统(Monitor Camera Imaging System, MCIS)来捕获成对数据</strong>，并使用图像构造来生成两种类型的OLED显示器的点扩散函数(PSF)，使用UNet的一个变体将UDC图像恢复问题解决为一个盲去卷积问题</p>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626172472059.png" srcset="/img/loading.gif" lazyload alt="1626172472059">
<ul>
<li>使用一块屏幕进行显示，然后将摄像机放在OLED屏幕后面采集数据，这块OLED屏幕会通过拿下来再放置上去来得到图像对，这难免会造成很多影响（<strong>偏移、倾斜等</strong> ）</li>
</ul>
</li>
<li>这项开创性工作有几个缺点:
<ul>
<li>由于实际和合成PSF之间的不匹配，PSF不准确</li>
<li>在MCIS捕获的数据中<strong>缺乏适当的高动态范围(high dynamic range, HDR)，缺少真实的UDC退化</strong>
<ul>
<li>虽然MCIS通常用于计算成像领域以捕获系统PSF或获取成对图像数据，但大多数商品监视器缺乏高动态范围，而<strong>高动态范围是模拟UDC系统中真实衍射伪影所必需的</strong></li>
<li>因此<strong>他们使用的PSF具有不完整的旁瓣，并且图像产生的伪影（例如模糊、阴影和眩光）比较浅</strong>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626092195900.png" srcset="/img/loading.gif" lazyload alt="1626092195900"></li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/C:%5CUsers%5Cpan%5CDesktop%5C%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%5C1626092238569.png" srcset="/img/loading.gif" lazyload alt="1626092238569"></li>
<li>在本文的工作中，作者<strong>在数据生成和PSF测量中考虑了HDR，从而能够正确处理真实场景</strong></li>
</ul>
</li>
</ul>
</li>
<li>原型UDC与实际生产的UDC显著不同</li>
<li>缺少对非MCIS数据的真实世界评估
<ul>
<li>作者在他们的设置中使用常规的OLED手动覆盖相机，而不是实际的刚性UDC组件，对准真实数据进行实验和评估</li>
<li>因此，显示器相对于传感器平面的任何轻微移动、旋转或倾斜都会导致PSF的变化</li>
</ul>
</li>
<li>提出的网络没有充分利用领域知识
<ul>
<li>尽管作者在数据合成中捕获并使用了PSF，但只是<strong>通过一个简单的UNet将UDC图像恢复公式化为一个盲去噪卷积问题</strong>，而没有明确地利用PSF作为有用的领域知识</li>
<li>相比之下，本文利用PSF作为DISCNet中的重要支持信息</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>在这项工作中，作者旨在解决上述问题</p>
<ul>
<li>首先提出了一个真实的图像形成模型和测量协议，考虑了<strong>场景和相机传感器的适当动态范围</strong>，并恢复了真实世界中退化的UDC图像</li>
<li>为此<strong>试验了最早生产的UDC设备之一——中兴Axon  20，它在自拍相机中加入了UDC系统</strong>
<ul>
<li>这里作者的目的是分析和研究衍射效应造成的伪像，而不是为中兴手机摄像头提出一个产品就绪的解决方案。该方法是通用的，并且可应用于其他UDC设备，或者<strong>更广泛的其他衍射受限成像系统</strong>，例如显微镜成像、针孔照相机</li>
</ul>
</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626093707637.png" srcset="/img/loading.gif" lazyload alt="1626093707637"></li>
<li>作者设计了一个成像系统，用点光源直接测量UDC设备的PSF。如图所示，由于显示器的衍射，产生的PSF具有一些特殊的特性: <strong>空间支撑大，中心响应强，长尾低能旁瓣</strong></li>
<li>利用测量的PSF，重新构建了图像形成模型，以<strong>解决由于场景的有限动态范围而缺失的真实耀斑、雾霾和模糊</strong></li>
<li>然后作者开发了一个基于图像形成模型的数据模拟流程，使用HDR图像来逼近真实场景</li>
<li>此外使用UDC手机的自拍相机捕捉<strong>真实图像</strong>，以验证模拟数据并评估恢复网络的性能</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626093919998.png" srcset="/img/loading.gif" lazyload alt="1626093919998"></li>
<li>如图所示，模拟和真实数据显示了类似的退化，尤其是在那些高强度区域。具体来说，耀斑可以在强光源附近观察到，在强光源处，<strong>高光以结构化衍射图案扩散到相邻的低强度区域</strong></li>
</ul>
</li>
<li>
<p>为了恢复UDC图像，作者提出了一种动态跳跃连接网络(DISCNet)，它将图像形成模型的领域知识结合到网络设计中</p>
<ul>
<li>传感器饱和破坏了基于PSF的卷积的移位不变性，导致空间变化的退化。这促使我们设计一个动态滤波器网络来动态预测每个像素的滤波器</li>
<li>此外，由于PSF的大规模空间支持，提出了多尺度架构，并在特征域进行动态卷积，以获得更大的感受野。此外，还引入了一个条件编码器来利用PSF的信息</li>
</ul>
</li>
<li>
<p>综上所述，本文贡献如下</p>
<ul>
<li>通过考虑动态范围和饱和度重新构建了UDC系统的成像模型，其中考虑了UDC图像中常见的衍射光斑</li>
<li>利用第一批UDC智能手机原型来测量真实世界的PSF
<ul>
<li>PSF用作基于模型的数据合成流程的一部分，以生成逼真的降级图像</li>
</ul>
</li>
<li>设计了一个动态跳跃连接网络(DISCNet)，它结合了UDC图像形成模型的领域知识
<ul>
<li>实验结果表明，这种方法能有效地消除衍射图像伪影</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Image-Formation-Model-and-Dataset">Image Formation Model and Dataset</h3>
<ul>
<li><strong>UDC的真实图像形成模型遭受几种类型的退化，包括衍射效应、饱和度和相机噪声，从而构建了退化模型</strong>：
<ul>
<li>$\hat{y}=\phi[C(x * k+n)]$
<ul>
<li>其中 $x$ 代表<strong>具有高动态范围(HDR)的真实场景的光照度</strong></li>
<li>$k$ 是已知的卷积核，即点扩散函数(PSF)，然后和 $x$ 进行二维卷积操作</li>
<li>$n$ 模拟相机噪声</li>
<li>为了对从<strong>数字传感器的有限动态范围</strong>中导出的饱和度进行建模，我们应用了由 $C(x) = min(x,x_{max})$ 表示的限幅操作 $C(\cdot)$ ，其中 $x_{max}$ 是范围阈值</li>
<li>非线性增强映射函数（non-linear tone mapping function） $\phi(\cdot)$ 用于匹配人类对场景的感知，还有一些相机的响应函数等操作</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_tonemap</span>(<span class="hljs-params">self, x, <span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;simple&#x27;</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span> == <span class="hljs-string">&#x27;mu_law&#x27;</span>:<br>        norm_x = x / x.<span class="hljs-built_in">max</span>()<br>        mapped_x = np.log(<span class="hljs-number">1</span> + <span class="hljs-number">10000</span> * norm_x) / np.log(<span class="hljs-number">1</span> + <span class="hljs-number">10000</span>)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span> == <span class="hljs-string">&#x27;simple&#x27;</span>:<br>        mapped_x = x / (x + <span class="hljs-number">0.25</span>)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span> == <span class="hljs-string">&#x27;same&#x27;</span>:<br>        mapped_x = x<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&#x27;tone mapping type [&#123;:s&#125;] is not recognized.&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">type</span>))<br>    <span class="hljs-keyword">return</span> mapped_x<br></code></pre></td></tr></table></figure>
<h4 id="PSF-Measurement">PSF Measurement</h4>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/C:%5CUsers%5Cpan%5CDesktop%5C%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%5C1626092238569.png" srcset="/img/loading.gif" lazyload alt="1626092238569"></li>
<li>给定单位幅度点源输入，传感器捕获的光场 $U_S(p,q)$ 可以表示为
<ul>
<li>$\begin{aligned} U_{S}(p, q)=&amp;\left{\left[\exp \left(\frac{i \pi r^{2}}{\lambda z_{1}}\right) \cdot t(p, q)\right] * \exp \left(\frac{i \pi r^{2}}{\lambda d}\right)\right.\ &amp; \left.\cdot \exp \left(\frac{-i \pi r^{2}}{\lambda f}\right)\right} * \exp \left(\frac{i \pi r^{2}}{\lambda z_{2}}\right) \end{aligned}$
<ul>
<li>这里的 $(p,q)$ 表示为二维坐标， $r^2 = p^2 + q^2$</li>
<li>$\lambda$ 为波长， $f$ 是镜头的焦距， $t(p,q)$ 是显示器的传输函数</li>
<li>$z_1,d,z_2$ 分别表示光源和显示器之间的距离、显示器和透镜之间的距离以及透镜和传感器之间的距离</li>
<li>$*$ 表示卷积， $\cdot$ 表示乘积</li>
</ul>
</li>
<li>最后，成像系统的PSF由 $k=\left|U_{S}\right|^{2}$ 给出</li>
<li>ps：这一部分都是光学上的东西，不过可以在相关论文上找到公式推导和实验结果等
<ul>
<li>顾梦涛, 宋祥磊, 张彪, 等. 基于波动光学的显微光场成像点扩散函数. 北京航空航天大学学报, 2019, 45(8): 1552-1559.</li>
</ul>
</li>
</ul>
</li>
<li>有了某个显示器的精确像素布局，那么就可以<strong>从理论上模拟在显示器条件下的光学系统的PSF</strong>
<ul>
<li>然而尽管模拟和真实测量的PSF具有相似的形状，但由于<strong>模型近似和制造缺陷</strong>，它们在颜色和对比度上略有不同</li>
<li>此外，我们无法访问在这项工作中使用的OLED的传输函数 $t( p, q)$ ，由于其自身原因，像素结构未知</li>
</ul>
</li>
<li>因此，作者设计了一个成像系统，通过将白点光源放置在离OLED显示器1米远的地方来直接测量峰值功率因数。在这个距离上，点光源的大小相当于传感器的一个像素，因此该光源可被视为脉冲输入</li>
<li>为了捕获整个PSF，包括强主峰和弱旁瓣，在不同的曝光下（1，1/32，1/768）连续拍摄三幅图像，然后将其归一化为相同的亮度水平</li>
<li>UDC系统的捕获PSF显示了结构化模式
<ul>
<li><strong>中心的响应(表示为主峰)非常强</strong>，并且具有更大能量</li>
<li>与普通相机的PSF相比，它<strong>具有更大的空间支撑(超过800  ×  800)和能量指数下降的尖峰形长尾旁瓣</strong></li>
<li>在旁瓣的尾部区域，可以观察到<strong>明显的颜色偏移</strong></li>
</ul>
</li>
<li>如果将同一场景<strong>从高动态范围剪辑到低动态范围，这些由衍射引起的耀斑将变得不可见</strong></li>
<li>由于输入场景的高动态范围，数字传感器(通常为10位)在实际应用中不可避免地会饱和，导致信息丢失
<ul>
<li>在成像模型中也应该考虑这个因素</li>
</ul>
</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626140101133.png" srcset="/img/loading.gif" lazyload alt="1626140101133">
<ul>
<li>UDC和普通摄像机的PSF能量比较。PSF被增亮以可视化结构化旁瓣模式</li>
<li>由于有限的光圈大小和制造缺陷，<strong>普通相机的PSF将是某种大小的模糊内核，而不是完美的点</strong></li>
</ul>
</li>
</ul>
<h4 id="Data-Collection-and-Simulation">Data Collection and Simulation</h4>
<ul>
<li>为了生成合成数据，作者从HDRI haven数据集收集了132幅动态范围大的HDR图像（分辨率为8192×4096的360度全景图像）
<ul>
<li>首先将这些全景图像重新投影回透视图，然后将它们裁剪成800×800的patches块</li>
<li>这样总共获得了2016张用于训练的子图像和360张用于测试的子图像</li>
<li>对于每种裁剪出来的图像，使用上面提到的方程模拟了相应的退化图像（校准的PSF用作内核k）</li>
</ul>
</li>
<li>对于每个真实场景，使用中兴 Axon 20手机拍摄了三张不同曝光（1，1/4，1/16）的图像，然后将它们组合成一张HDR图像
<ul>
<li>为了保证数据的线性，作者直接使用了HDR融合后的原始数据，没有进行任何非线性处理</li>
</ul>
</li>
</ul>
<h4 id="Dynamic-Skip-Connection-Network">Dynamic Skip Connection Network</h4>
<ul>
<li>
<p>动机</p>
<ul>
<li>将UDC图像恢复视为一个非盲图像恢复问题
<ul>
<li>给定退化图像 ${ \hat y_i }$ 和GT退化信息（PSF） ${ k_i }$ ，来去恢复得到清晰图像  ${ x_i }$</li>
<li><strong>在已知卷积核的情况下</strong>，非盲恢复建立了盲恢复的上限</li>
<li>可以通过结合任何 PSF 估计算法用于盲 UDC 图像恢复</li>
</ul>
</li>
<li>PSF 的形状和强度会<strong>根据输入像素及其在相应位置的邻域而变化</strong>
<ul>
<li>例如 OLED 将饱和高光衍射到相邻的不饱和区域，促使从附近区域截取信息的适应性恢复</li>
</ul>
</li>
<li>受最近成功的卷积核预测网络(Kernel Prediction Network, KPN) 的启发，作者提出了动态跳跃连接网络(DISCNet)
<ul>
<li>它在每个像素动态生成卷积核，并将其应用于具有跳跃连接的不同网络层的不同特征空间</li>
<li>该网络以两个输入为条件以促进恢复空间变化的退化图像
<ul>
<li>提供关于图像形成模型的领域知识的PSF</li>
<li>提供光强度和邻域上下文信息</li>
</ul>
</li>
<li>对于动态卷积，像大多数现有的基于KPN的方法一样，在图像域中直接应用预测滤波器并不最适合UDC图像恢复，因为UDC中的PSF具有大的支持度和长尾旁瓣
<ul>
<li>这种具有大PSF的逆卷积过程只能在具有足够大的核(大于100)的图像域中很好地近似，而动态滤波器的尺寸通常要小得多(例如5或7)</li>
</ul>
</li>
<li>因此，作者建议<strong>在特征域中应用动态卷积</strong>。除此之外作者还构建了一个多尺度架构，其中每个尺度上的滤波器生成器分别预测动态滤波器，以进一步扩大学习滤波器的空间支持</li>
</ul>
</li>
</ul>
</li>
<li>
<p>网络结构</p>
<ul>
<li>
<p><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626148304608.png" srcset="/img/loading.gif" lazyload alt="1626148304608"></p>
</li>
<li>
<p>网络包括一个<strong>恢复分支</strong>和一个<strong>动态跳跃连接网络</strong></p>
<ul>
<li>恢复分支学习提取特征并恢复最终的干净图像</li>
<li>DISCNet用于处理各种退化，并转换和细化从恢复分支提取的特征</li>
</ul>
</li>
<li>
<p>Restoration Branch</p>
<ul>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626148321728.png" srcset="/img/loading.gif" lazyload alt="1626148321728"></li>
<li>an encoder-decoder architecture with skip connections</li>
<li>编码器包含三个卷积块，每个卷积块都有一个步长为2的3 × 3卷积层、一个LeakyReLU层和两个残差块</li>
<li>通过编码器得到三种不同尺度的特征 $E_1, E_2, E_3$ ，提取的特征被送入DISCNet，并分别转换成 $R_1,R_2,R_3$</li>
<li>解码器由两个卷积块组成，包括一个上采样卷积层和两个残差块
<ul>
<li>每个卷积块以其相应尺度的变换特征作为输入，并重构最终增强映射的清晰图像</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Dynamic Skip Connection Network</p>
<ul>
<li>
<p><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626166163139.png" srcset="/img/loading.gif" lazyload alt="1626166163139"></p>
</li>
<li>
<p>假设退化图像 $\hat y_i$ 的尺寸为 $H \times W \times C$ ，通过Principal Component Analysis (PCA) 将PSF投影到一个 b 维的向量上，称为kernel code，大小为 $H \times W \times b$ ，降低计算复杂度</p>
<ul>
<li>在本文中，根据经验设置 $b = 5$</li>
</ul>
</li>
<li>
<p>之后将这部分和退化图像直接拼接，得到大小为 $H \times W \times (C+b)$ 的条件图，然后将其输入到DISCNet</p>
</li>
<li>
<p>提出的DISCNet主要包括三种设计:条件编码器、多尺度滤波器生成器、动态卷积</p>
</li>
<li>
<p>条件编码器使用<strong>类似于恢复分支的编码器</strong>的3个网络块来获取特定比例的特征 $H_1,H_2,H_3$</p>
</li>
<li>
<p>尽管kernel code 映射是全局统一的，但条件编码器仍然可以从具有空间可变性的退化图像中捕获丰富的信息，并设法从附近的低光区域恢复饱和信息</p>
</li>
<li>
<p>然后提取得到的不同尺度的特征被输入到它们相应的滤波器生成器</p>
<ul>
<li>其中每个滤波器生成器包括3 × 3卷积层、两个残差块和1 × 1卷积层以扩展特征维度</li>
</ul>
</li>
<li>
<p>给定动态滤波器 $s$ 的大小，滤波器生成器 $G_n$ 以特定的比例提取的特征 $H_n \in \mathbb{R}^{h \times w \times c}$ 作为输入，输出预测滤波器 $F_n = G_n(H_n)$ ，其中 $F_n \in \mathbb{R}^{h \times w \times cs^2}$ 。然后动态卷积使用这些滤波器来细化特征 $E_n$</p>
</li>
<li>
<p>对于特征 $E_n \in {h \times w \times c}$ 的每一个像素点 $(i,j,c_m)$ ，其输出 $R_n$ 为</p>
<ul>
<li>$R_{n}\left(i, j, c_{m}\right)=\left\langle K_{n}\left(i, j, c_{m}\right), \varphi\left(E_{n}\left(i, j, c_{m}\right)\right)\right\rangle$</li>
<li>其中 $K_{n}\left(i, j, c_{m}\right)$ 是一个从  $F_n(i,j,c_m) \in \mathbb{R}^{1 \times 1 \times s^2}$ reshape 得到的 $s \times s$ 的卷积核</li>
<li>$\varphi(\cdot)$ 表示以 $(i,j,c_m)$  为中心  $s \times s$ 大小的patch</li>
<li>$\langle \rangle$ 表示内积运算，然后将 $R_n$ 投射到修复分支中</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Experiments-2">Experiments</h3>
<ul>
<li>为了评估DISCNet对于非盲降级的有效性，作者旋转了PSF
<ul>
<li>类似于在成像系统中围绕光轴旋转显示器</li>
<li>为了考虑旋转角度的变化，构建了一个内核集，其中角度在(-12，12)范围内变化，其中0弧度指的是原始PSF</li>
</ul>
</li>
<li>这种设置下，每个降级的图像都用方程模拟得到，在训练过程中，子图像被随机裁剪成256 × 256大小的patch</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626227193659.png" srcset="/img/loading.gif" lazyload alt="1626227193659">
<ul>
<li>在只有1个内核的数据集上训练的baseline很容易过度拟合到单个降级数据集，无法推广到其他降级类型
<ul>
<li>由于假设的PSF和真实的PSF之间的差异，在其他数据集上的性能严重下降</li>
</ul>
</li>
<li>即使是最简单的单尺度动态卷积设计也有利于特征细化</li>
</ul>
</li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228205814.png" srcset="/img/loading.gif" lazyload alt="1626228205814"></li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228369489.png" srcset="/img/loading.gif" lazyload alt="1626228369489"></li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228394714.png" srcset="/img/loading.gif" lazyload alt="1626228394714"></li>
<li><img src="/2021/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x19/1626228513343.png" srcset="/img/loading.gif" lazyload alt="1626228513343"></li>
</ul>
<h3 id="Discussion">Discussion</h3>
<ul>
<li>本文的工作只是消除UDC系统中衍射图像伪影的第一步，而其他的复杂性，例如空间变化的功率谱、弱光下的噪声和散焦，需要更多的研究</li>
<li>所提出的DISCNet有时会由于模拟数据和真实数据之间的域差距而失败，例如相机噪声、运动模糊、场景变化等</li>
<li>定义了一个基于物理的图像形成模型，测量了UDC系统的真实世界PSF，并提供了一个基于模型的数据合成流程来生成真实的图像</li>
<li>作者还提出了一种新的基于领域知识的动态跳跃连接网络来恢复UDC图像。为进一步探索UDC图像复原提供了基础</li>
<li>本文对UDC的观点有潜力能够激发更多衍射受限的图像恢复工作</li>
</ul>
<h3 id="Code">Code</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#############################</span><br><span class="hljs-comment"># Kernel Prediction Branch</span><br><span class="hljs-comment">#############################</span><br><span class="hljs-keyword">if</span> self.kernel_cond:<br>    <span class="hljs-keyword">if</span> self.kernel_cond == <span class="hljs-string">&#x27;img&#x27;</span>:<br>        cond_nc = in_nc<br>    <span class="hljs-keyword">elif</span> self.kernel_cond == <span class="hljs-string">&#x27;psf&#x27;</span>:<br>        cond_nc = psf_nc<br>    <span class="hljs-keyword">elif</span> self.kernel_cond == <span class="hljs-string">&#x27;img-psf&#x27;</span>:<br>        cond_nc = in_nc + psf_nc<br><br>    self.kconv_11 = conv_block(cond_nc, nf, kernel_size=kernel_size, act_type=act_type)<br>    self.kconv_12 = ResBlock(nf, res_scale=res_scale, act_type=act_type)<br>    self.kconv_13 = ResBlock(nf, res_scale=res_scale, act_type=act_type)<br><br>    <span class="hljs-keyword">if</span> self.multi_scale:<br>        self.dynamic_kernel1 = nn.Sequential(<br>            conv_block(nf, nf, kernel_size=kernel_size),<br>            ResBlock(nf, res_scale=res_scale, act_type=act_type),<br>            ResBlock(nf, res_scale=res_scale, act_type=act_type),<br>            conv_block(nf, nf * (kpn_sz ** <span class="hljs-number">2</span>), kernel_size=<span class="hljs-number">1</span>))<br><br>    self.kconv_21 = conv_block(nf, <span class="hljs-number">2</span>*nf, stride=<span class="hljs-number">2</span>, kernel_size=kernel_size, act_type=act_type)<br>    self.kconv_22 = ResBlock(<span class="hljs-number">2</span>*nf, res_scale=res_scale, act_type=act_type)<br>    self.kconv_23 = ResBlock(<span class="hljs-number">2</span>*nf, res_scale=res_scale, act_type=act_type)<br><br>    <span class="hljs-keyword">if</span> self.multi_scale:<br>        self.dynamic_kernel2 = nn.Sequential(<br>            conv_block(<span class="hljs-number">2</span>*nf, <span class="hljs-number">2</span>*nf, kernel_size=kernel_size),<br>            ResBlock(<span class="hljs-number">2</span>*nf, res_scale=res_scale, act_type=act_type),<br>            ResBlock(<span class="hljs-number">2</span>*nf, res_scale=res_scale, act_type=act_type),<br>            conv_block(<span class="hljs-number">2</span>*nf, <span class="hljs-number">2</span>*nf * (kpn_sz ** <span class="hljs-number">2</span>), kernel_size=<span class="hljs-number">1</span>))<br><br>    self.kconv_31 = conv_block(<span class="hljs-number">2</span>*nf, <span class="hljs-number">4</span>*nf, stride=<span class="hljs-number">2</span>, kernel_size=kernel_size, act_type=act_type)<br>    self.kconv_32 = ResBlock(<span class="hljs-number">4</span>*nf, res_scale=res_scale, act_type=act_type)<br>    self.kconv_33 = ResBlock(<span class="hljs-number">4</span>*nf, res_scale=res_scale, act_type=act_type)<br><br>    self.dynamic_kernel = nn.Sequential(<br>        conv_block(<span class="hljs-number">4</span>*nf, <span class="hljs-number">4</span>*nf, kernel_size=kernel_size),<br>        ResBlock(<span class="hljs-number">4</span>*nf, res_scale=res_scale, act_type=act_type),<br>        ResBlock(<span class="hljs-number">4</span>*nf, res_scale=res_scale, act_type=act_type),<br>        conv_block(<span class="hljs-number">4</span>*nf, <span class="hljs-number">4</span>*nf * (kpn_sz ** <span class="hljs-number">2</span>), kernel_size=<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#############################</span><br><span class="hljs-comment"># Kernel Prediction Branch</span><br><span class="hljs-comment">#############################</span><br><span class="hljs-comment"># kernel network</span><br><span class="hljs-keyword">if</span> self.kernel_cond:<br>    <span class="hljs-keyword">if</span> self.kernel_cond == <span class="hljs-string">&#x27;img&#x27;</span>:<br>        cond_x = x<br>    <span class="hljs-keyword">elif</span> self.kernel_cond == <span class="hljs-string">&#x27;psf&#x27;</span>:<br>        cond_x = psf.expand(-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, x.shape[<span class="hljs-number">2</span>], x.shape[<span class="hljs-number">3</span>])<br>    <span class="hljs-keyword">elif</span> self.kernel_cond == <span class="hljs-string">&#x27;img-psf&#x27;</span>:<br>        cond_x = psf.expand(-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, x.shape[<span class="hljs-number">2</span>], x.shape[<span class="hljs-number">3</span>])<br>        cond_x = torch.cat((cond_x, x), dim=<span class="hljs-number">1</span>)<br>	<span class="hljs-comment"># condition encoder</span><br>    kfea1 = self.kconv_13(self.kconv_12(self.kconv_11(cond_x)))<br>    kfea2 = self.kconv_23(self.kconv_22(self.kconv_21(kfea1)))<br>    kfea3 = self.kconv_33(self.kconv_32(self.kconv_31(kfea2)))<br>    <br>    <span class="hljs-keyword">if</span> self.multi_scale:<br>        dynamic_kernel1 = self.dynamic_kernel1(kfea1)<br>        dynamic_kernel2 = self.dynamic_kernel2(kfea2)<br>    dynamic_kernel = self.dynamic_kernel(kfea3)<br>    <br><br>    <br><span class="hljs-comment"># Dynamic convolution</span><br><span class="hljs-keyword">if</span> self.kernel_cond:<br>    fea3 = kernel2d_conv(fea3, dynamic_kernel, self.kpn_sz)<br><br><span class="hljs-comment"># Decoder</span><br><span class="hljs-keyword">if</span> self.multi_scale:<br>    fea2 = kernel2d_conv(fea2, dynamic_kernel2, self.kpn_sz)<br>    upfea2 = self.upconv_23(self.upconv_22(self.upconv_21(fea3) + fea2))<br><span class="hljs-keyword">else</span>:<br>    upfea2 = self.upconv_23(self.upconv_22(self.upconv_21(fea3) + fea2))<br><br><span class="hljs-keyword">if</span> self.multi_scale:<br>    fea1 = kernel2d_conv(fea1, dynamic_kernel1, self.kpn_sz)<br>    upfea1 = self.upconv_13(self.upconv_12(self.upconv_11(upfea2) + fea1))<br><span class="hljs-keyword">else</span>:<br>    upfea1 = self.upconv_13(self.upconv_12(self.upconv_11(upfea2) + fea1))<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">kernel2d_conv</span>(<span class="hljs-params">feat_in, kernel, ksize</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    If you have some problems in installing the CUDA FAC layer, </span><br><span class="hljs-string">    you can consider replacing it with this Python implementation.</span><br><span class="hljs-string">    Thanks @AIWalker-Happy for his implementation.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    channels = feat_in.size(<span class="hljs-number">1</span>)<br>    N, kernels, H, W = kernel.size()<br>    pad_sz = (ksize - <span class="hljs-number">1</span>) // <span class="hljs-number">2</span><br><br>    <span class="hljs-comment"># 边缘pad</span><br>    feat_in = F.pad(feat_in, (pad_sz, pad_sz, pad_sz, pad_sz), mode=<span class="hljs-string">&quot;replicate&quot;</span>)<br>    <span class="hljs-comment"># 将输入按照ksize进行切割</span><br>    feat_in = feat_in.unfold(<span class="hljs-number">2</span>, ksize, <span class="hljs-number">1</span>).unfold(<span class="hljs-number">3</span>, ksize, <span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 做一些变换</span><br>    feat_in = feat_in.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>).contiguous()<br>    feat_in = feat_in.reshape(N, H, W, channels, -<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 尺度变换</span><br>    kernel = kernel.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>).reshape(N, H, W, channels, ksize, ksize)<br>    kernel = kernel.permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>).reshape(N, H, W, channels, -<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 内积</span><br>    feat_out = torch.<span class="hljs-built_in">sum</span>(feat_in * kernel, axis=-<span class="hljs-number">1</span>)<br>    feat_out = feat_out.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous()<br>    <span class="hljs-keyword">return</span> feat_out<br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/study/" class="category-chain-item">study</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E4%B8%8E%E5%9B%BE%E5%83%8F%E6%81%A2%E5%A4%8D/" class="print-no-link">#图像增强与图像恢复</a>
      
        <a href="/tags/%E9%AB%98%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA/" class="print-no-link">#高光谱图像去噪</a>
      
        <a href="/tags/%E7%BB%84%E4%BC%9A%E5%88%86%E4%BA%AB/" class="print-no-link">#组会分享</a>
      
        <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" class="print-no-link">#目标检测</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>论文阅读-0x19</div>
      <div>http://example.com/2021/06/05/论文阅读-0x19/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>hyzs1220</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2021年6月5日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/08/31/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x20/" title="论文阅读-0x20">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">论文阅读-0x20</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/05/22/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-0x18/" title="论文阅读-0x18">
                        <span class="hidden-mobile">论文阅读-0x18</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
